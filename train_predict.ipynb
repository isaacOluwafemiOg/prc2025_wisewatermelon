{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:19.631450Z",
     "iopub.status.busy": "2025-11-29T11:42:19.629534Z",
     "iopub.status.idle": "2025-11-29T11:42:19.969253Z",
     "shell.execute_reply": "2025-11-29T11:42:19.968279Z",
     "shell.execute_reply.started": "2025-11-29T11:42:19.631186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Standard Library Imports ---\n",
    "from pathlib import Path  # Object-oriented filesystem paths\n",
    "import warnings           # Handling warning messages\n",
    "\n",
    "# --- Data Manipulation & Linear Algebra ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Scikit-Learn: Metrics & Preprocessing ---\n",
    "from sklearn.metrics import mean_squared_error       # Evaluation metric\n",
    "from sklearn.preprocessing import LabelEncoder       # Categorical encoding\n",
    "from sklearn.model_selection import StratifiedGroupKFold # specific CV strategy for grouped data\n",
    "\n",
    "# --- Modeling ---\n",
    "from catboost import Pool, CatBoostRegressor         # Gradient Boosting algorithm\n",
    "\n",
    "# Configuration: Ignore benign warnings to keep the notebook clean\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:19.971708Z",
     "iopub.status.busy": "2025-11-29T11:42:19.971223Z",
     "iopub.status.idle": "2025-11-29T11:42:19.976749Z",
     "shell.execute_reply": "2025-11-29T11:42:19.975498Z",
     "shell.execute_reply.started": "2025-11-29T11:42:19.971683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Raw Data Directories ---\n",
    "# Directories containing granular flight sensor data\n",
    "TRAIN_FLIGHTS_DIR = '../prc-2025-datasets/flights_train'\n",
    "RANK_FLIGHTS_DIR  = '../prc-2025-datasets/flights_rank'\n",
    "FINAL_FLIGHTS_DIR = '../prc-2025-datasets/flights_final'\n",
    "\n",
    "# --- Flight Metadata Lists ---\n",
    "# Parquet files containing the list of flights for each phase\n",
    "FLIGHTLIST_TRAIN = '../prc-2025-datasets/flightlist_train.parquet'\n",
    "FLIGHTLIST_RANK  = '../prc-2025-datasets/flightlist_rank.parquet'\n",
    "FLIGHTLIST_FINAL = '../prc-2025-datasets/flightlist_final.parquet'\n",
    "\n",
    "# --- Target & Submission Files ---\n",
    "# Fuel consumption data (Ground truth for train, Submission templates for rank/final)\n",
    "FUEL_TRAIN = '../prc-2025-datasets/fuel_train.parquet'\n",
    "FUEL_RANK  = '../prc-2025-datasets/fuel_rank_submission.parquet'\n",
    "FUEL_FINAL = '../prc-2025-datasets/fuel_final_submission.parquet'\n",
    "\n",
    "# --- Auxiliary Data ---\n",
    "# Airport information (likely coordinates, runway info, etc.)\n",
    "AIRPORTS = '../prc-2025-datasets/apt.parquet'\n",
    "\n",
    "# --- Output Paths ---\n",
    "# Path to load the preprocessed training dataset\n",
    "PREPARED_TRAIN_DATA = './prep_train_acropole.csv'\n",
    "PREPARED_RANK_DATA = './prep_rank_acropole.csv'\n",
    "PREPARED_FINAL_DATA = './prep_final_acropole.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:20.020872Z",
     "iopub.status.busy": "2025-11-29T11:42:20.020472Z",
     "iopub.status.idle": "2025-11-29T11:42:20.037211Z",
     "shell.execute_reply": "2025-11-29T11:42:20.036001Z",
     "shell.execute_reply.started": "2025-11-29T11:42:20.020845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FLIGHTS_DIR = Path(TRAIN_FLIGHTS_DIR)\n",
    "RANK_FLIGHTS_DIR = Path(RANK_FLIGHTS_DIR)\n",
    "FINAL_FLIGHTS_DIR = Path(FINAL_FLIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:20.039196Z",
     "iopub.status.busy": "2025-11-29T11:42:20.038325Z",
     "iopub.status.idle": "2025-11-29T11:42:20.518077Z",
     "shell.execute_reply": "2025-11-29T11:42:20.517017Z",
     "shell.execute_reply.started": "2025-11-29T11:42:20.039157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load all necessary data\n",
    "train_flightlist = pd.read_parquet(FLIGHTLIST_TRAIN)\n",
    "rank_flightlist = pd.read_parquet(FLIGHTLIST_RANK)\n",
    "final_flightlist = pd.read_parquet(FLIGHTLIST_FINAL)\n",
    "airports = pd.read_parquet(AIRPORTS)\n",
    "train_fuel = pd.read_parquet(FUEL_TRAIN)\n",
    "rank_fuel = pd.read_parquet(FUEL_RANK)\n",
    "final_fuel = pd.read_parquet(FUEL_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:22.421153Z",
     "iopub.status.busy": "2025-11-29T11:42:22.420778Z",
     "iopub.status.idle": "2025-11-29T11:42:35.674443Z",
     "shell.execute_reply": "2025-11-29T11:42:35.673440Z",
     "shell.execute_reply.started": "2025-11-29T11:42:22.421115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# read the prepared train data\n",
    "prep_train = pd.read_csv(PREPARED_TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:36.021689Z",
     "iopub.status.busy": "2025-11-29T11:42:36.021392Z",
     "iopub.status.idle": "2025-11-29T11:42:36.027331Z",
     "shell.execute_reply": "2025-11-29T11:42:36.026430Z",
     "shell.execute_reply.started": "2025-11-29T11:42:36.021663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def haversine(lat_lon1, lat_lon2):\n",
    "    \"\"\"\n",
    "    Calculates the great-circle distance between two points on the earth's surface\n",
    "    using the Haversine formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat_lon1 : tuple or list of float\n",
    "        The first coordinate pair in degrees: (latitude, longitude).\n",
    "    lat_lon2 : tuple or list of float\n",
    "        The second coordinate pair in degrees: (latitude, longitude).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The distance between the two points in meters.\n",
    "    \"\"\"\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Unpack and convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1 = map(np.radians, lat_lon1)\n",
    "    lat2, lon2 = map(np.radians, lat_lon2)\n",
    "    \n",
    "    # Apply Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    # Return distance converted to meters (km * 1000)\n",
    "    return R * c * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:36.028486Z",
     "iopub.status.busy": "2025-11-29T11:42:36.028186Z",
     "iopub.status.idle": "2025-11-29T11:42:36.052739Z",
     "shell.execute_reply": "2025-11-29T11:42:36.051731Z",
     "shell.execute_reply.started": "2025-11-29T11:42:36.028458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extra_features(df, datetime_cols=[\"timestamp\"]):\n",
    "    \"\"\"\n",
    "    Generates additional geospatial and temporal features for the flight data.\n",
    "    \n",
    "    Processing Steps:\n",
    "    1. Calculates Great Circle Distance between Origin and Destination.\n",
    "    2. Converts specified timestamp columns to datetime objects.\n",
    "    3. Calculates segment duration in minutes.\n",
    "    4. Drops original raw timestamp columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe containing flight logs. Must include:\n",
    "        ['orig_lat', 'orig_long', 'dest_lat', 'dest_long', 'seg_start', 'seg_end']\n",
    "    datetime_cols : list, optional\n",
    "        List of columns to convert to datetime objects and subsequently drop.\n",
    "        Default is [\"timestamp\"].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The modified dataframe with new features and dropped timestamp columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate Full Flight Distance (Origin -> Destination) in meters\n",
    "    # Uses the previously defined 'haversine' function row-by-row\n",
    "    df['full_flight_distance'] = df.apply(\n",
    "        lambda row: haversine(\n",
    "            (row['orig_lat'], row['orig_long']),\n",
    "            (row['dest_lat'], row['dest_long'])\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 2. Standardize Datetime Columns\n",
    "    # Convert string timestamps to datetime objects (UTC)\n",
    "    for dt_col in datetime_cols:\n",
    "        if dt_col in df.columns:\n",
    "            df[dt_col] = pd.to_datetime(df[dt_col], format='ISO8601', utc=True)\n",
    "   \n",
    "    # 3. Calculate Segment Duration\n",
    "    # Difference between segment end and start, converted to minutes\n",
    "    # Note: Ensure 'seg_end' and 'seg_start' are already in datetime format \n",
    "    # (or included in the datetime_cols list if they are strings initially)\n",
    "    df['seg_duration'] = (df['seg_end'] - df['seg_start']).dt.total_seconds() / 60\n",
    "\n",
    "    # 4. Cleanup\n",
    "    # Remove the original datetime columns (models usually require numerical/encoded inputs)\n",
    "    result_df = df.drop(columns=datetime_cols)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the temporal columns representing key flight events\n",
    "# These are passed to the function to be converted/used for duration calc, then dropped\n",
    "dt_feat = ['takeoff', 'landed', 'seg_start', 'seg_end']\n",
    "\n",
    "# Apply feature engineering:\n",
    "# - Calculates Great Circle Distance (Origin -> Destination)\n",
    "# - Computes segment duration (in minutes)\n",
    "# - Removes the raw datetime columns listed in 'dt_feat'\n",
    "train_interact = extra_features(prep_train, dt_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:56.916599Z",
     "iopub.status.busy": "2025-11-29T11:42:56.916193Z",
     "iopub.status.idle": "2025-11-29T11:42:56.922709Z",
     "shell.execute_reply": "2025-11-29T11:42:56.921697Z",
     "shell.execute_reply.started": "2025-11-29T11:42:56.916568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List of categorical features to be encoded\n",
    "# Includes operational data (Origin/Dest), technical specs (Engine, Wake), and classification codes\n",
    "cols_to_encode = [\n",
    "    'aircraft_type', 'origin_icao', 'destination_icao',\n",
    "    'WAKE', 'ENG_NAME', 'ENG_MAN', 'ENG_MODEL', 'Manufacturer',\n",
    "    'Physical_Class_Engine', 'AAC', 'AAC_minimum', 'AAC_maximum', 'ADG',\n",
    "    'TDG', 'Main_Gear_Config', 'ICAO_WTC', 'Class', 'FAA_Weight', 'CWT',\n",
    "    'One_Half_Wake_Category', 'Two_Wake_Category_Appx_A',\n",
    "    'Two_Wake_Category_Appx_B', 'SRS', 'flaps_type', 'engine_type',\n",
    "    'engine_mount', 'engine_default', 'eng_type', 'eng_manufacturer',\n",
    "    'fuel_engine', 'fuel_aircraft'\n",
    "]\n",
    "\n",
    "# Dictionary to store the fitted encoder objects for each column\n",
    "# This allows consistent transformation of Test/Rank data later\n",
    "encoder_dict = {}\n",
    "\n",
    "for col in cols_to_encode:\n",
    "    # Initialize a new LabelEncoder for this column\n",
    "    sp_enc = LabelEncoder()\n",
    "    \n",
    "    # Fit the encoder on the training data\n",
    "    # Note: We cast to 'str' to handle potential NaN values or mixed types gracefully\n",
    "    sp_enc.fit(train_interact[col].astype('str'))\n",
    "    \n",
    "    # Store the encoder\n",
    "    encoder_dict[col] = sp_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:58.802464Z",
     "iopub.status.busy": "2025-11-29T11:42:58.801983Z",
     "iopub.status.idle": "2025-11-29T11:42:59.616262Z",
     "shell.execute_reply": "2025-11-29T11:42:59.615172Z",
     "shell.execute_reply.started": "2025-11-29T11:42:58.802431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Iterate through the list of categorical columns\n",
    "for col in cols_to_encode:\n",
    "    # Retrieve the specific encoder fitted for this column\n",
    "    encoder = encoder_dict[col]\n",
    "    \n",
    "    # Transform the text data to integers\n",
    "    # .astype('str') ensures we handle NaNs as the string 'nan', consistent with the .fit() step\n",
    "    train_interact[col] = encoder.transform(train_interact[col].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:42:59.669262Z",
     "iopub.status.busy": "2025-11-29T11:42:59.668885Z",
     "iopub.status.idle": "2025-11-29T11:42:59.845119Z",
     "shell.execute_reply": "2025-11-29T11:42:59.844240Z",
     "shell.execute_reply.started": "2025-11-29T11:42:59.669233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Feature Selection ---\n",
    "\n",
    "# List of columns to remove from the feature set\n",
    "# These include unique identifiers, redundant names, and raw date strings\n",
    "cols_to_drop = [\n",
    "    'flight_id', 'origin_name', 'destination_name', 'flight_date', 'MODEL',\n",
    "    'aircraft', 'eng_name', 'eng_uid', 'flight_start', 'flight_end',\n",
    "    'takeoff_date', 'land_date'\n",
    "]\n",
    "\n",
    "# Create Feature Matrix (X)\n",
    "# Drop the target ('fuel_kg') and the unused columns\n",
    "X = train_interact.drop(columns=['fuel_kg'] + cols_to_drop)\n",
    "\n",
    "# Create Target Vector (y)\n",
    "y = train_interact['fuel_kg']\n",
    "\n",
    "# Keep track of categorical indices for the CatBoost model\n",
    "cat_cols = cols_to_encode\n",
    "\n",
    "# --- 2. Stratification Key ---\n",
    "\n",
    "# Create a custom column to guide the Cross-Validation split.\n",
    "# We combine 'missing_segment' status and 'aircraft_type' to ensure\n",
    "# the validation set reflects the diversity of data quality and aircraft models.\n",
    "stratifier = train_interact['missing_segment'].astype('str') + '_' + train_interact['aircraft_type'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:43:00.707853Z",
     "iopub.status.busy": "2025-11-29T11:43:00.707584Z",
     "iopub.status.idle": "2025-11-29T11:43:00.723982Z",
     "shell.execute_reply": "2025-11-29T11:43:00.722986Z",
     "shell.execute_reply.started": "2025-11-29T11:43:00.707831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List of features selected through iterative experimentation and feature importance analysis.\n",
    "# These variables yielded the best RMSE performance during cross-validation.\n",
    "\n",
    "sel_ind = [\n",
    "    # --- Segment Dynamics & Aggregates ---\n",
    "    'rawseg_diff_mean', 'flight_DE_ct', 'seg_ENR_dur', 'all_seg_phase_dur',\n",
    "    'start_longitude', 'min_longitude', 'dest_long',\n",
    "    'end_altitude', 'mean_altitude', 'sum_altitude', 'total_climb_height',\n",
    "    'sum_groundspeed', 'sum_CAS', # CAS: Calibrated Airspeed\n",
    "    \n",
    "    # --- Fuel & Engine Telemetry Proxies ---\n",
    "    'unscaled_approx_seg_fuel', 'nancount_mach', \n",
    "    'sum_fuel_flow', 'sum_fuel', 'sum_drag', \n",
    "    'start_thrust', 'sum_thrust', 'end_auth_score',\n",
    "    \n",
    "    # --- Previous Segment/Accumulated Fuel Metrics ---\n",
    "    'sum_cl_fuel', 'sum_enr_fuel', 'sum_dist_from_ades', \n",
    "    'start_acp_fuel', 'max_acp_fuel', 'sum_acp_fuel', 'sum_acp_fuelflow',\n",
    "    \n",
    "    # --- Static Aircraft Specifications ---\n",
    "    'Tail_Height_at_OEW_ft',\n",
    "    'MALW_lb',   # Maximum Aircraft Landing Weight\n",
    "    'mtow',      # Maximum Takeoff Weight\n",
    "    'wing_mac',  # Mean Aerodynamic Chord\n",
    "    'drag_gears',\n",
    "    \n",
    "    # --- Engine Characteristics & Emissions ---\n",
    "    'eng_bpr',        # Engine Bypass Ratio\n",
    "    'eng_ei_co_co',   # Emission Index (Carbon Monoxide)\n",
    "    'eng_ei_co_app', \n",
    "    'eng_ei_nox_co',\n",
    "    \n",
    "    # --- Calculated Interaction Features ---\n",
    "    'full_flight_distance', \n",
    "    'seg_duration'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:43:00.802755Z",
     "iopub.status.busy": "2025-11-29T11:43:00.802445Z",
     "iopub.status.idle": "2025-11-29T11:43:00.813991Z",
     "shell.execute_reply": "2025-11-29T11:43:00.812746Z",
     "shell.execute_reply.started": "2025-11-29T11:43:00.802731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optimal hyperparameters derived from Optuna optimization\n",
    "# Target Benchmark: 5-Fold CV RMSE ~= 213.90\n",
    "hyp = {\n",
    "    # --- Ensemble Structure ---\n",
    "    'iterations': 972,                # Total number of trees\n",
    "    'max_depth': 6,                   # Depth of the tree (controls interaction complexity)\n",
    "    'learning_rate': 0.05060963202084587, # Step size shrinkage used in update to prevent overfitting\n",
    "    \n",
    "    # --- Regularization & Sampling ---\n",
    "    'l2_leaf_reg': 1.822777238628044, # L2 regularization term on cost function\n",
    "    'min_data_in_leaf': 78,           # Minimum number of samples in a leaf (smooths the model)\n",
    "    \n",
    "    # --- Stochastic Features (Randomness) ---\n",
    "    'colsample_bylevel': 0.6035766248956298, # Fraction of features selected at each tree level\n",
    "    'subsample': 0.46633222868063806,        # Fraction of data samples used for each tree\n",
    "    'bootstrap_type': 'MVS'                  # 'Minimum Variance Sampling' (CatBoost specific sampling)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:43:00.815532Z",
     "iopub.status.busy": "2025-11-29T11:43:00.815118Z",
     "iopub.status.idle": "2025-11-29T11:44:13.822438Z",
     "shell.execute_reply": "2025-11-29T11:44:13.821129Z",
     "shell.execute_reply.started": "2025-11-29T11:43:00.815505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 5fold rmse train:  135.50833061642936\n",
      "mean 5fold rmse test:  213.89598165883922\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CV Setup ---\n",
    "# Initialize the cross-validator\n",
    "scv = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "# Containers to store results and data for post-analysis\n",
    "fit_models = []\n",
    "ll_scores = []      # Hold-out (Validation) scores\n",
    "train_scores = []   # Training scores (to check for overfitting)\n",
    "\n",
    "# Storage for debugging/analysis (dictionaries mapped by fold index)\n",
    "train_features, train_targets = {}, {}\n",
    "valid_features, valid_targets = {}, {}\n",
    "valid_preds = {}\n",
    "\n",
    "ind = 0\n",
    "\n",
    "# --- 2. Training Loop ---\n",
    "# Split data ensuring Flight IDs do not leak between Train and Test\n",
    "for train_index, test_index in scv.split(X, stratifier, groups=train_interact['flight_id']):\n",
    "    \n",
    "    # A. Split Data\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] \n",
    "\n",
    "    # Store raw splits for later analysis\n",
    "    train_features[ind] = X_train\n",
    "    train_targets[ind] = y_train\n",
    "    valid_features[ind] = X_test\n",
    "    valid_targets[ind] = y_test\n",
    "    \n",
    "    # B. Feature Subset Selection\n",
    "    # Reduce feature space to the selected 'sel_ind' list\n",
    "    preppedtrain_sel = X_train[sel_ind]\n",
    "    preppedtest_sel = X_test[sel_ind]\n",
    "\n",
    "    # Identify indices of categorical features within the selected subset\n",
    "    # CatBoost requires specific indices for categorical handling\n",
    "    cat_features = [i for i, col in enumerate(sel_ind) if col in cat_cols]\n",
    "            \n",
    "    # Create optimized CatBoost Pools\n",
    "    train_pool = Pool(preppedtrain_sel, y_train, cat_features=cat_features)\n",
    "    test_pool = Pool(preppedtest_sel, y_test, cat_features=cat_features)\n",
    "    \n",
    "    # C. Model Initialization & Fitting\n",
    "    model = CatBoostRegressor(\n",
    "        objective='RMSE',\n",
    "        task_type='CPU',\n",
    "        random_state=42,\n",
    "        silent=True,\n",
    "        **hyp  # Unpack optimal hyperparameters\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "    fit_models.append(model)\n",
    "\n",
    "    # D. Prediction & Post-Processing\n",
    "    # Predict on Validation Set\n",
    "    y_pred = model.predict(preppedtest_sel)\n",
    "    \n",
    "    # Physics Constraint: Fuel cannot be negative. \n",
    "    # Clip predictions to the minimum observed fuel in the training set (or global minimum)\n",
    "    # Note: Ensure 'train_fuel' is defined globally, otherwise replace with y_train.min()\n",
    "    min_fuel_threshold = train_fuel['fuel_kg'].min() \n",
    "    y_pred = np.where(y_pred < 0, min_fuel_threshold, y_pred)\n",
    "\n",
    "    valid_preds[ind] = y_pred\n",
    "    ind += 1\n",
    "\n",
    "    # Predict on Training Set (for bias/variance analysis)\n",
    "    train_pred = model.predict(preppedtrain_sel)\n",
    "    train_pred = np.where(train_pred < 0, min_fuel_threshold, train_pred)\n",
    "    \n",
    "    # E. Evaluation\n",
    "    ind_cv = mean_squared_error(y_test, y_pred, squared=False) # RMSE\n",
    "    tr_cv = mean_squared_error(y_train, train_pred, squared=False)\n",
    "\n",
    "    ll_scores.append(ind_cv)\n",
    "    train_scores.append(tr_cv)\n",
    "\n",
    "# --- 3. Summary Output ---\n",
    "print(f'Mean 5-Fold RMSE Train: {np.mean(train_scores):.4f}') \n",
    "print(f'Mean 5-Fold RMSE Test:  {np.mean(ll_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:44:19.775507Z",
     "iopub.status.busy": "2025-11-29T11:44:19.775245Z",
     "iopub.status.idle": "2025-11-29T11:44:20.105638Z",
     "shell.execute_reply": "2025-11-29T11:44:20.104222Z",
     "shell.execute_reply.started": "2025-11-29T11:44:19.775485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-processed ranking/test data\n",
    "# (Ensure PREPARED_RANK_DATA is defined in your config section, similar to PREPARED_TRAIN_DATA)\n",
    "prep_rank = pd.read_csv(PREPARED_RANK_DATA)\n",
    "\n",
    "# 1. Apply Feature Engineering\n",
    "# Generate the same interaction features (Distances, Durations) as the training set\n",
    "rank_interact = extra_features(prep_rank, dt_feat)\n",
    "\n",
    "# 2. Apply Categorical Encoding\n",
    "# We iterate through the encoders fitted on the training set\n",
    "for col in cols_to_encode:\n",
    "    # Optimization: Only transform columns that are actually part of the final feature set ('sel_ind')\n",
    "    if col in sel_ind:\n",
    "        # Transform using the stored dictionary to ensure mapping consistency (Train vs Rank)\n",
    "        # .astype('str') handles potential data type mismatches or NaNs\n",
    "        rank_interact[col] = encoder_dict[col].transform(rank_interact[col].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:44:20.106818Z",
     "iopub.status.busy": "2025-11-29T11:44:20.106578Z",
     "iopub.status.idle": "2025-11-29T11:44:20.229398Z",
     "shell.execute_reply": "2025-11-29T11:44:20.228393Z",
     "shell.execute_reply.started": "2025-11-29T11:44:20.106800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Ensemble Prediction ---\n",
    "\n",
    "# Generate predictions from each of the 5 cross-validated models\n",
    "preds = [\n",
    "    np.clip(\n",
    "        model.predict(rank_interact[sel_ind]),  # Predict using selected features\n",
    "        a_min=train_fuel['fuel_kg'].min(),      # Lower bound: Min observed training fuel\n",
    "        a_max=None                              # Upper bound: No restriction\n",
    "    ) \n",
    "    for model in fit_models\n",
    "]\n",
    "\n",
    "# --- Averaging ---\n",
    "\n",
    "# Calculate the mean prediction across all folds (Model Ensembling)\n",
    "# This reduces the variance of the error and generally improves generalization\n",
    "pred = sum(preds) / len(preds)\n",
    "\n",
    "# Assign the final averaged prediction to the ranking dataframe\n",
    "rank_fuel['fuel_kg'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:44:20.260082Z",
     "iopub.status.busy": "2025-11-29T11:44:20.259163Z",
     "iopub.status.idle": "2025-11-29T11:44:20.307731Z",
     "shell.execute_reply": "2025-11-29T11:44:20.306965Z",
     "shell.execute_reply.started": "2025-11-29T11:44:20.260049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24289.000000\n",
       "mean       416.292326\n",
       "std        745.771351\n",
       "min          0.453592\n",
       "25%         92.157918\n",
       "50%        151.403112\n",
       "75%        394.877050\n",
       "max      12200.323908\n",
       "Name: fuel_kg, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_fuel['fuel_kg'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:48:23.411864Z",
     "iopub.status.busy": "2025-11-29T11:48:23.411568Z",
     "iopub.status.idle": "2025-11-29T11:48:23.434699Z",
     "shell.execute_reply": "2025-11-29T11:48:23.433747Z",
     "shell.execute_reply.started": "2025-11-29T11:48:23.411843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the predictions for submission\n",
    "rank_fuel.to_parquet('wise-watermelon_v26.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:39:48.189223Z",
     "iopub.status.busy": "2025-11-29T12:39:48.188837Z",
     "iopub.status.idle": "2025-11-29T12:39:55.224888Z",
     "shell.execute_reply": "2025-11-29T12:39:55.223829Z",
     "shell.execute_reply.started": "2025-11-29T12:39:48.189197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/3462117581.py:1: DtypeWarning: Columns (347,348,349,350,351,352,353,354,361,362,363,364,365,366,367,373,374,376,377,378,379,380,391,392,394,395,396,397,398,399,401,404,423,432,433,435,447,448,449,450,477,479) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prep_final = pd.read_csv('/kaggle/input/prc2025-accessories/prep_final_acropole/prep_final_acropole.csv')\n"
     ]
    }
   ],
   "source": [
    "prep_final = pd.read_csv('/kaggle/input/prc2025-accessories/prep_final_acropole/prep_final_acropole.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:04.143851Z",
     "iopub.status.busy": "2025-11-29T12:40:04.143521Z",
     "iopub.status.idle": "2025-11-29T12:40:14.442212Z",
     "shell.execute_reply": "2025-11-29T12:40:14.441117Z",
     "shell.execute_reply.started": "2025-11-29T12:40:04.143827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_interact = extra_features(prep_final,dt_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:17.089580Z",
     "iopub.status.busy": "2025-11-29T12:40:17.089252Z",
     "iopub.status.idle": "2025-11-29T12:40:17.112809Z",
     "shell.execute_reply": "2025-11-29T12:40:17.111859Z",
     "shell.execute_reply.started": "2025-11-29T12:40:17.089555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in cols_to_encode:\n",
    "    if col in sel_ind:\n",
    "        print(col)\n",
    "        final_interact[col] = encoder_dict[col].transform(final_interact[col].astype('str'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:22.461344Z",
     "iopub.status.busy": "2025-11-29T12:40:22.461009Z",
     "iopub.status.idle": "2025-11-29T12:40:22.743220Z",
     "shell.execute_reply": "2025-11-29T12:40:22.742068Z",
     "shell.execute_reply.started": "2025-11-29T12:40:22.461319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds_final = [np.clip(model.predict(final_interact[sel_ind]),\n",
    "                a_min=train_fuel['fuel_kg'].min(),a_max=None) for model in fit_models]\n",
    "preds_final = sum(preds_final) / len(preds_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:24.939684Z",
     "iopub.status.busy": "2025-11-29T12:40:24.939339Z",
     "iopub.status.idle": "2025-11-29T12:40:24.945566Z",
     "shell.execute_reply": "2025-11-29T12:40:24.944674Z",
     "shell.execute_reply.started": "2025-11-29T12:40:24.939659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_fuel['fuel_kg'] = preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:26.646674Z",
     "iopub.status.busy": "2025-11-29T12:40:26.645819Z",
     "iopub.status.idle": "2025-11-29T12:40:26.659667Z",
     "shell.execute_reply": "2025-11-29T12:40:26.658940Z",
     "shell.execute_reply.started": "2025-11-29T12:40:26.646644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    61745.000000\n",
       "mean       512.410579\n",
       "std        830.672808\n",
       "min          0.453592\n",
       "25%        107.267244\n",
       "50%        360.601572\n",
       "75%        471.461127\n",
       "max      13004.959405\n",
       "Name: fuel_kg, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fuel['fuel_kg'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T12:40:37.123530Z",
     "iopub.status.busy": "2025-11-29T12:40:37.122822Z",
     "iopub.status.idle": "2025-11-29T12:40:37.206505Z",
     "shell.execute_reply": "2025-11-29T12:40:37.205371Z",
     "shell.execute_reply.started": "2025-11-29T12:40:37.123501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_fuel.to_parquet('wise-watermelon_final.parquet')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3553924,
     "sourceId": 6191509,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8568721,
     "sourceId": 13854478,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8761454,
     "sourceId": 13919748,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
