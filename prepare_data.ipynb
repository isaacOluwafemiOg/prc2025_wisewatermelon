{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331d7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\acropole\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\USER\\miniconda3\\envs\\acropole\\Lib\\site-packages\\acropole\\estimator.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Import Dependencies\n",
    "# ---------------------------------------------------------------\n",
    "# This section loads all external libraries required for:\n",
    "#   • Data manipulation and numerical computation (pandas, numpy)\n",
    "#   • Flight trajectory parsing, visualization, and aeronautical data (traffic)\n",
    "#   • Aircraft performance models (OpenAP)\n",
    "#   • Fuel estimation using ACROPOLE models\n",
    "#   • Miscellaneous utilities such as file paths and display tools\n",
    "#\n",
    "# Notes:\n",
    "# - Warnings are intentionally suppressed for cleaner notebook output.\n",
    "# - All imported modules are used in downstream processing of flight\n",
    "#   trajectories,feature generation, and fuel estimation.\n",
    "# ================================================================\n",
    "\n",
    "from pathlib import Path                     # Cross-platform filesystem path handling\n",
    "\n",
    "import pandas as pd                          # Primary data manipulation library\n",
    "import numpy as np                           # Numerical computing and array utilities\n",
    "\n",
    "# ---------------------- Traffic Library -------------------------\n",
    "# traffic.core.Traffic  -> Handles flight trajectories and ADS-B/Mode-S time series\n",
    "# traffic.data.airports -> Provides airport metadata (lat/lon, elevation, etc.)\n",
    "# traffic.data.navaids  -> Provides navigational aids (VOR, NDB, FIX)\n",
    "from traffic.core import Traffic\n",
    "from traffic.data import airports as t_airports\n",
    "from traffic.data import navaids\n",
    "\n",
    "# ---------------------- OpenAP Models ---------------------------\n",
    "# prop          -> Aircraft properties (mass, wingspan, reference area, etc.)\n",
    "# FlightPhase   -> Automated flight-phase detection (CL, CR, DE, LVL, NA)\n",
    "# Drag          -> Drag model: aerodynamic drag estimates\n",
    "# Thrust        -> Engine thrust models\n",
    "# FuelFlow      -> Fuel burn estimation based on power settings and flight conditions\n",
    "from openap import prop\n",
    "from openap.phase import FlightPhase\n",
    "from openap.drag import Drag\n",
    "from openap.thrust import Thrust\n",
    "from openap import FuelFlow\n",
    "\n",
    "# ---------------------- ACROPOLE Fuel Model ---------------------\n",
    "# Advanced, calibrated fuel estimation tool for flight segments\n",
    "from acropole import FuelEstimator\n",
    "\n",
    "import math                                   # Mathematical utilities\n",
    "\n",
    "# ---------------------- Warning Suppression ---------------------\n",
    "# Suppress RuntimeWarning and UserWarning to avoid clutter during long computations.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f0876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Pandas display configuration\n",
    "# ---------------------------------------------------------------\n",
    "# Ensure that all columns of any DataFrame are shown when displayed.\n",
    "# This prevents column truncation, which is especially useful for\n",
    "# inspecting wide flight-segment datasets with many engineered features.\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36af40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Dataset and Resource Paths\n",
    "# ---------------------------------------------------------------\n",
    "# Centralized definitions of all dataset locations used throughout\n",
    "# the notebook. These paths point to:\n",
    "#   • Flight trajectory folders for training, ranking, and final sets\n",
    "#   • Flight metadata (flightlists)\n",
    "#   • Fuel measurement and submission files\n",
    "#   • Airport reference datasets\n",
    "#   • FAA aircraft performance and characteristics\n",
    "#\n",
    "# Storing paths in named constants improves maintainability and\n",
    "# makes it easier to switch between environments or folder\n",
    "# structures without editing downstream code.\n",
    "# ================================================================\n",
    "\n",
    "TRAIN_FLIGHTS_DIR   = '../prc-2025-datasets/flights_train'          # Raw trajectory files for training flights\n",
    "RANK_FLIGHTS_DIR    = '../prc-2025-datasets/flights_rank'           # Trajectory files for phase 1 ranking\n",
    "FINAL_FLIGHTS_DIR   = '../prc-2025-datasets/flights_final'          # Trajectory files for final submission (phase 2)\n",
    "\n",
    "FLIGHTLIST_TRAIN    = '../prc-2025-datasets/flightlist_train.parquet' # Metadata for training flights\n",
    "FLIGHTLIST_RANK     = '../prc-2025-datasets/flightlist_rank.parquet'  # Metadata for ranking flights\n",
    "FLIGHTLIST_FINAL    = '../prc-2025-datasets/flightlist_final.parquet' # Metadata for final submission flights\n",
    "\n",
    "FUEL_RANK           = '../prc-2025-datasets/fuel_rank_submission.parquet' # output template for phase 1 predictions\n",
    "FUEL_TRAIN          = '../prc-2025-datasets/fuel_train.parquet'           # Ground-truth fuel for model training\n",
    "FUEL_FINAL          = '../prc-2025-datasets/fuel_final_submission.parquet' # Output template for final predictions\n",
    "\n",
    "AIRPORTS            = '../prc-2025-datasets/apt.parquet'              # Provided airport reference dataset\n",
    "WORLD_AIRPORTS      = '../World_Airports.csv'                         # External global airport database\n",
    "FAA_AIRCRAFT_DATA   = '../aircraft_data.xlsx'                         # FAA aircraft specs to augment available features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ec2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Convert directory strings to Path objects\n",
    "# ---------------------------------------------------------------\n",
    "# Converting dataset directory paths from raw strings to pathlib.Path\n",
    "# objects provides several advantages:\n",
    "#   • OS-independent path handling (Windows, Linux, macOS)\n",
    "#   • Easier path concatenation using \"/\" operator\n",
    "# This makes downstream code more readable and robust.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "TRAIN_FLIGHTS_DIR = Path(TRAIN_FLIGHTS_DIR)\n",
    "RANK_FLIGHTS_DIR  = Path(RANK_FLIGHTS_DIR)\n",
    "FINAL_FLIGHTS_DIR = Path(FINAL_FLIGHTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659782c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Load Core Datasets\n",
    "# ---------------------------------------------------------------\n",
    "# This section reads all required parquet files into memory.\n",
    "# These datasets include:\n",
    "#   • Flight metadata for training, ranking, and final evaluation\n",
    "#   • Airport reference data\n",
    "#   • Fuel measurements for training, as well as the\n",
    "#     submission template for the ranking and final phases.\n",
    "#\n",
    "# ================================================================\n",
    "\n",
    "train_flightlist = pd.read_parquet(FLIGHTLIST_TRAIN)   # Flight metadata (training set)\n",
    "rank_flightlist  = pd.read_parquet(FLIGHTLIST_RANK)    # Flight metadata (ranking submission set)\n",
    "final_flightlist = pd.read_parquet(FLIGHTLIST_FINAL)   # Flight metadata (final submission set)\n",
    "\n",
    "airports = pd.read_parquet(AIRPORTS)                   # Airport reference information\n",
    "\n",
    "train_fuel = pd.read_parquet(FUEL_TRAIN)               # Ground-truth fuel for training\n",
    "rank_fuel  = pd.read_parquet(FUEL_RANK)                # Template for phase 1 fuel predictions\n",
    "final_fuel = pd.read_parquet(FUEL_FINAL)               # Template for final fuel predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7aa389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Collect unique aircraft types across all datasets\n",
    "# ---------------------------------------------------------------\n",
    "# The PRC dataset is split into training, ranking, and final sets.\n",
    "# To ensure complete coverage when building aircraft-specific models\n",
    "# or loading aircraft performance data (e.g., OpenAP, FAA specs),\n",
    "# we compile a unified list of all aircraft types appearing in:\n",
    "#   • train_flightlist\n",
    "#   • rank_flightlist\n",
    "#   • final_flightlist\n",
    "#\n",
    "# This guarantees that downstream preprocessing and feature\n",
    "# engineering can handle every aircraft type present in the competition.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "all_aircraft_types = (\n",
    "    pd.concat([rank_flightlist, final_flightlist, train_flightlist])\n",
    "      ['aircraft_type']\n",
    "      .unique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26f2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Remove Known Problematic Flights from the Training Fuel Dataset\n",
    "# ---------------------------------------------------------------\n",
    "# Several flights in the provided dataset contain invalid or\n",
    "# inconsistent trajectory or fuel data. These abnormalities would\n",
    "# degrade model training, so they are explicitly excluded.\n",
    "#\n",
    "# Summary of removed flights:\n",
    "#\n",
    "# 1. prc790175280  \n",
    "#    - Contains a segment lasting ~39 minutes with only start/end\n",
    "#      trajectory points.\n",
    "#    - Altitude barely changes (33998 → 33997 ft), yet fuel\n",
    "#      consumption exceeds 30,000 kg for a B744 — physically unrealistic.\n",
    "#\n",
    "# 2. prc777924876\n",
    "#    - Early timestamps show extremely erratic position data.\n",
    "#    - Trajectory begins at unrealistic altitudes prior to recorded\n",
    "#      takeoff.\n",
    "#    - Training fuel targets exist only for this invalid pre–takeoff\n",
    "#      region.\n",
    "#\n",
    "# 3. prc799064748\n",
    "#    - Total recorded flight time between KCOS and KDEN is ~20 minutes,\n",
    "#      which is operationally impossible for this route and aircraft.\n",
    "#\n",
    "# 4. prc776443417 and prc776502511\n",
    "#    - These two IDs refer to the *same flight*, each containing\n",
    "#      complementary portions of the trajectory.\n",
    "#    - Resolution:\n",
    "#         • Keep prc776443417 in the training labels\n",
    "#         • Remove prc776502511 from train_fuel\n",
    "#         • Later, when generating training trajectories,\n",
    "#           load both trajectories and merge them under ID prc776443417\n",
    "#\n",
    "# 5. prc778592434, prc778582087, prc778566666\n",
    "#    - These three are also duplicate/complementary trajectories.\n",
    "#    - Resolution:\n",
    "#         • Keep prc778592434\n",
    "#         • Remove prc778582087 and prc778566666 from train_fuel\n",
    "#         • Later concatenate their trajectories under the surviving ID\n",
    "#\n",
    "# Only the fuel labels are filtered here; trajectory merging is handled\n",
    "# during feature preparation.\n",
    "# ================================================================\n",
    "\n",
    "elim_flights = [\n",
    "    'prc776502511',\n",
    "    'prc778582087',\n",
    "    'prc778566666',\n",
    "    'prc790175280',\n",
    "    'prc799064748',\n",
    "    'prc777924876',\n",
    "]\n",
    "\n",
    "# Remove problematic flight IDs from the training fuel dataset\n",
    "train_fuel = (\n",
    "    train_fuel[~train_fuel['flight_id'].isin(elim_flights)]\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc5c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafcfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Supplement Missing Airport Elevation Data\n",
    "# ---------------------------------------------------------------\n",
    "# The provided airport dataset (apt.parquet) contains missing values\n",
    "# in the `elevation` field for some ICAO airports. Accurate elevation\n",
    "# is important for:\n",
    "#   • determining pressure altitude\n",
    "#   • computing atmospheric properties\n",
    "#   • estimating takeoff/landing fuel usage\n",
    "#\n",
    "# To correct this, we supplement missing elevations using an external\n",
    "# global airport dataset:\n",
    "#   Source: Kaggle — \"World Airports\"\n",
    "#   URL: https://kaggle.com/datasets/mexwell/world-airports\n",
    "#\n",
    "# Steps:\n",
    "#   1. Identify airports with missing elevation in the provided dataset.\n",
    "#   2. Load the external dataset.\n",
    "#   3. Filter out any airports that still lack elevation in the external data.\n",
    "#   4. Keep only those airports whose ICAO codes match the missing entries.\n",
    "#   5. Extract a mapping {ICAO -> elevation_ft} for patching.\n",
    "#\n",
    "# The resulting dictionary `supplement_airport_elev` will be used later\n",
    "# to fill missing elevations in the main airport table.\n",
    "# ================================================================\n",
    "\n",
    "# Identify airports missing elevation in the competition dataset\n",
    "missing_airport_elev = airports[airports['elevation'].isna()]['icao'].unique()\n",
    "\n",
    "# Load external world airport database (contains elevation_ft)\n",
    "world_airport = pd.read_csv(WORLD_AIRPORTS)\n",
    "\n",
    "# Keep only rows with valid elevation data\n",
    "world_airport_no_missing_elev = world_airport[~world_airport['elevation_ft'].isna()]\n",
    "\n",
    "# Filter to only the airports whose elevation is missing in our dataset\n",
    "world_airport_no_missing_elev = world_airport_no_missing_elev[\n",
    "    world_airport_no_missing_elev['airport_ident'].isin(missing_airport_elev)\n",
    "]\n",
    "\n",
    "# Reindex so ICAO codes act as keys\n",
    "world_airport_no_missing_elev.index = world_airport_no_missing_elev['airport_ident']\n",
    "\n",
    "# Convert to dictionary for easy lookup during patching\n",
    "supplement_airport_elev = world_airport_no_missing_elev['elevation_ft'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2952ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Complete Missing Airport Elevations Using Traffic Library Sources\n",
    "# ---------------------------------------------------------------\n",
    "# After supplementing missing airport elevations using the external\n",
    "# World Airports dataset, some ICAO codes may still not have a value.\n",
    "# For these remaining airports, we attempt two fallback strategies:\n",
    "#\n",
    "#   1. traffic.data.airports (t_airports)\n",
    "#        • Provides airport metadata, including altitude (in feet or meters\n",
    "#          depending on source).\n",
    "#        • Some airports in the competition dataset may be found here even\n",
    "#          if not present in the external Kaggle dataset.\n",
    "#\n",
    "#   2. traffic.data.navaids (navaids)\n",
    "#        • As a last resort, use the altitude of a nearby navaid sharing\n",
    "#          the same ICAO identifier (rare, but can exist).\n",
    "#\n",
    "# Any airport for which both lookups fail remains missing and will be\n",
    "# handled later (typically ignored or filled with model-dependent defaults).\n",
    "# ================================================================\n",
    "\n",
    "for mis_air in missing_airport_elev:\n",
    "    if mis_air not in supplement_airport_elev:\n",
    "        # Attempt to retrieve elevation from traffic's airport database\n",
    "        try:\n",
    "            supplement_airport_elev[mis_air] = t_airports[mis_air].altitude\n",
    "        except Exception:\n",
    "            # Fallback: try retrieving altitude from a matching navaid\n",
    "            try:\n",
    "                supplement_airport_elev[mis_air] = navaids.get(mis_air).altitude\n",
    "            except Exception:\n",
    "                # Leave missing if no reliable source exists\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22a6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Manually supplement elevation for ZGOW (source: https://acukwik.com/Airport-Info/ZGOW)\n",
    "#     Altitude = 51 ft\n",
    "# ================================================================\n",
    "\n",
    "supplement_airport_elev['ZGOW'] = 51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50ad7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Fill missing airport elevations in the main dataset\n",
    "# ---------------------------------------------------------------\n",
    "# Using the dictionary `supplement_airport_elev` built from:\n",
    "#   • World Airports dataset\n",
    "#   • Traffic library (airports & navaids)\n",
    "#   • Manual supplements\n",
    "# we fill the missing `elevation` values in the main airports DataFrame.\n",
    "#\n",
    "# Logic:\n",
    "#   • If `elevation` is already present, keep it.\n",
    "#   • If missing, look up the ICAO code in `supplement_airport_elev`.\n",
    "# ================================================================\n",
    "\n",
    "airports['elevation'] = np.where(\n",
    "    airports['elevation'].isna(),\n",
    "    airports['icao'].map(supplement_airport_elev),\n",
    "    airports['elevation']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb15dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(198)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports['elevation'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f6ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Enrich Training Flight Metadata with Airport Coordinates & Elevations\n",
    "# ---------------------------------------------------------------\n",
    "# To compute features related to flight performance (e.g., takeoff/landing\n",
    "# weight, climb profiles), we augment each flight with its origin and\n",
    "# destination airport data:\n",
    "#   • Latitude\n",
    "#   • Longitude\n",
    "#   • Elevation\n",
    "#\n",
    "# Steps:\n",
    "# 1. Merge `train_flightlist` with `airports` on the origin ICAO code.\n",
    "#    - Columns renamed to `orig_lat`, `orig_long`, `orig_elev`.\n",
    "#    - Original `icao` column dropped after merge.\n",
    "# 2. Merge `train_flightlist` with `airports` on the destination ICAO code.\n",
    "#    - Columns renamed to `dest_lat`, `dest_long`, `dest_elev`.\n",
    "#    - Original `icao` column dropped after merge.\n",
    "# 3. Extract flight takeoff and landing dates from the timestamp columns.\n",
    "#    - Adds `takeoff_date` and `land_date` for daily-level analyses or\n",
    "#      grouping purposes.\n",
    "# ================================================================\n",
    "\n",
    "# Merge origin airport information\n",
    "train_flightlist = pd.merge(\n",
    "    train_flightlist,\n",
    "    airports,\n",
    "    left_on='origin_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "train_flightlist = train_flightlist.rename(\n",
    "    columns={'longitude':'orig_long', 'latitude':'orig_lat', 'elevation':'orig_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Merge destination airport information\n",
    "train_flightlist = pd.merge(\n",
    "    train_flightlist,\n",
    "    airports,\n",
    "    left_on='destination_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "train_flightlist = train_flightlist.rename(\n",
    "    columns={'longitude':'dest_long', 'latitude':'dest_lat', 'elevation':'dest_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Extract takeoff and landing dates for potential daily aggregations\n",
    "train_flightlist['takeoff_date'] = train_flightlist['takeoff'].dt.date\n",
    "train_flightlist['land_date'] = train_flightlist['landed'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3deea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Enrich Final Flight Metadata with Airport Coordinates & Elevations\n",
    "# ---------------------------------------------------------------\n",
    "# Similar to the training set, we augment each flight in the final\n",
    "# submission set with origin and destination airport information:\n",
    "#   • Latitude\n",
    "#   • Longitude\n",
    "#   • Elevation\n",
    "#\n",
    "# This ensures consistency in feature engineering across training\n",
    "# and submission datasets.\n",
    "#\n",
    "# Steps:\n",
    "# 1. Merge `final_flightlist` with `airports` on the origin ICAO code.\n",
    "#    - Rename columns to `orig_lat`, `orig_long`, `orig_elev`.\n",
    "#    - Drop redundant `icao` column.\n",
    "# 2. Merge `final_flightlist` with `airports` on the destination ICAO code.\n",
    "#    - Rename columns to `dest_lat`, `dest_long`, `dest_elev`.\n",
    "#    - Drop redundant `icao` column.\n",
    "# 3. Extract takeoff and landing dates for daily-level analyses or\n",
    "#    feature creation.\n",
    "# ================================================================\n",
    "\n",
    "# Merge origin airport information\n",
    "final_flightlist = pd.merge(\n",
    "    final_flightlist,\n",
    "    airports,\n",
    "    left_on='origin_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "final_flightlist = final_flightlist.rename(\n",
    "    columns={'longitude':'orig_long', 'latitude':'orig_lat', 'elevation':'orig_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Merge destination airport information\n",
    "final_flightlist = pd.merge(\n",
    "    final_flightlist,\n",
    "    airports,\n",
    "    left_on='destination_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "final_flightlist = final_flightlist.rename(\n",
    "    columns={'longitude':'dest_long', 'latitude':'dest_lat', 'elevation':'dest_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Extract takeoff and landing dates for potential daily aggregation or feature creation\n",
    "final_flightlist['takeoff_date'] = final_flightlist['takeoff'].dt.date\n",
    "final_flightlist['land_date'] = final_flightlist['landed'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91514f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Enrich Ranking Flight Metadata with Airport Coordinates & Elevations\n",
    "# ---------------------------------------------------------------\n",
    "# To maintain consistency with training and final datasets, we augment\n",
    "# each flight in the ranking/validation set with origin and destination\n",
    "# airport information:\n",
    "#   • Latitude\n",
    "#   • Longitude\n",
    "#   • Elevation\n",
    "#\n",
    "# This ensures that all feature engineering steps can be applied\n",
    "# uniformly across training, ranking, and final datasets.\n",
    "#\n",
    "# Steps:\n",
    "# 1. Merge `rank_flightlist` with `airports` on the origin ICAO code.\n",
    "#    - Rename columns to `orig_lat`, `orig_long`, `orig_elev`.\n",
    "#    - Drop the redundant `icao` column.\n",
    "# 2. Merge `rank_flightlist` with `airports` on the destination ICAO code.\n",
    "#    - Rename columns to `dest_lat`, `dest_long`, `dest_elev`.\n",
    "#    - Drop the redundant `icao` column.\n",
    "# 3. Extract takeoff and landing dates for daily-level feature creation.\n",
    "# ================================================================\n",
    "\n",
    "# Merge origin airport information\n",
    "rank_flightlist = pd.merge(\n",
    "    rank_flightlist,\n",
    "    airports,\n",
    "    left_on='origin_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "rank_flightlist = rank_flightlist.rename(\n",
    "    columns={'longitude':'orig_long', 'latitude':'orig_lat', 'elevation':'orig_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Merge destination airport information\n",
    "rank_flightlist = pd.merge(\n",
    "    rank_flightlist,\n",
    "    airports,\n",
    "    left_on='destination_icao',\n",
    "    right_on='icao',\n",
    "    how='left'\n",
    ")\n",
    "rank_flightlist = rank_flightlist.rename(\n",
    "    columns={'longitude':'dest_long', 'latitude':'dest_lat', 'elevation':'dest_elev'}\n",
    ").drop(['icao'], axis=1)\n",
    "\n",
    "# Extract takeoff and landing dates\n",
    "rank_flightlist['takeoff_date'] = rank_flightlist['takeoff'].dt.date\n",
    "rank_flightlist['land_date'] = rank_flightlist['landed'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b4a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Define Aircraft Type Specifications\n",
    "# ---------------------------------------------------------------\n",
    "# This dictionary contains detailed information about the aircraft\n",
    "# types appearing in the dataset. Information includes:\n",
    "#   • Model identifiers and ICAO codes\n",
    "#   • Aircraft class (L: large), wake turbulence category\n",
    "#   • Engine type, number, and optional manufacturer/model/thrust\n",
    "#   • Physical dimensions: length, wingspan, tail height\n",
    "#   • Performance metrics: range (nm), ceiling (ft), max speed, passenger capacity\n",
    "#\n",
    "# Source references:\n",
    "#   • 'https://github.com/atoff/OpenAircraftType/blob/master/src'\n",
    "#\n",
    "# Steps:\n",
    "# 1. Define `aircraft_type_dict` mapping ICAO codes to aircraft specifications.\n",
    "# 2. Convert dictionary to a pandas DataFrame for easier access and merging.\n",
    "# 3. Rename `ICAO` column to `aircraft_type` to match flight datasets.\n",
    "# ================================================================\n",
    "\n",
    "# Dictionary mapping ICAO codes to aircraft specifications\n",
    "\n",
    "aircraft_type_dict = {\n",
    "    'B789':{'MODEL':'787-9 Dreamliner','ICAO':'B789','CLASS':'L','WAKE':'H','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2},\n",
    "    'A359':{'MODEL':'A350-900','ICAO':'A359','CLASS':'L','WAKE':'H','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2,'ENG_NAME':'RR Trent XWB','ENG_MAN':'Rolls-Royce','ENG_MODEL':'Trent XWB',\n",
    "            'ENG_THRUST':374500,'LENGTH':66.8,'WINGSPAN':64.75,'TAIL_HEIGHT':17.05,'RANGE':8100,\n",
    "            'CEILING':43100,'MAX_SPEED':13,'PAX_CAP':325},\n",
    "    'B788':{'MODEL':'787-8 Dreamliner','ICAO':'B788','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'A332':{'MODEL':'A330-200','ICAO':'A332','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'GE CF6-80E/PW4000/RR Trent 700',\n",
    "            'ENG_MAN':'General Electric/Pratt & Whitney/Rolls-Royce',\n",
    "            'ENG_MODEL':'CF6-80E/PW4000/Trent 700','ENG_THRUST':316000,'LENGTH':58.82,\n",
    "            'WINGSPAN':60.3,'TAIL_HEIGHT':17.39,'RANGE':7250,'CEILING':41100,'MAX_SPEED':70,\n",
    "            'PAX_CAP':406},\n",
    "    'A21N':{'MODEL':'A321neo','ICAO':'A21N','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'PW1000G/CFM LEAP-1A','ENG_MAN':'Pratt & Whitney/CFM International',\n",
    "            'ENG_MODEL':'PW1000G/CFM LEAP-1A','ENG_THRUST':147300,'LENGTH':44.51,'WINGSPAN':35.8,\n",
    "            'RANGE':4000,'CEILING':39800,'MAX_SPEED':473,'PAX_CAP':240},\n",
    "    'A20N':{'MODEL':'A320neo','ICAO':'A20N','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'PW1000G/CFM LEAP-1A','ENG_MAN':'Pratt & Whitney/CFM International',\n",
    "            'ENG_MODEL':'PW1000G/CFM LEAP-1A','ENG_THRUST':120600,'LENGTH':37.57,'WINGSPAN':35.8,\n",
    "            'RANGE':3500,'CEILING':39800,'MAX_SPEED':473,'PAX_CAP':195},\n",
    "    'A320':{'MODEL':'A320','ICAO':'A320','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'IAE V2500/CFM56-5','ENG_MAN':'International Aero Engines/CFM International',\n",
    "            'ENG_MODEL':'IAE V2500/CFM56-5','ENG_THRUST':120000,'LENGTH':37.57,'WINGSPAN':35.8,\n",
    "            'TAIL_HEIGHT':11.76,'RANGE':3300,'CEILING':41000,'MAX_SPEED':470,'PAX_CAP':195},\n",
    "    'A333':{'MODEL':'A330-300','ICAO':'A333','CLASS':'L','WAKE':'H','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2,'ENG_NAME':'GE CF6-80E/PW4000/RR Trent 700',\n",
    "            'ENG_MAN':'General Electric/Pratt & Whitney/Rolls-Royce',\n",
    "            'ENG_MODEL':'CF6-80E/PW4000/Trent 700','ENG_THRUST':316000,'LENGTH':63.67,'WINGSPAN':60.3,\n",
    "            'TAIL_HEIGHT':17.39,'RANGE':6350,'CEILING':41100,'MAX_SPEED':470,'PAX_CAP':440},\n",
    "     'B734':{'MODEL':'737-400','ICAO':'B734','CLASS':'L','WAKE':'M','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2},\n",
    "    'B738':{'MODEL':'737-800','ICAO':'B738','CLASS':'L','WAKE':'M','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2},\n",
    "    'A321':{'MODEL':'A321','ICAO':'A321','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'IAE V2500A5/CFM56-5B','ENG_MAN':'International Aero Engines/CFM International',\n",
    "            'ENG_MODEL':'IAE V2500A5/CFM56-5B','ENG_THRUST':147000,'LENGTH':44.51,'WINGSPAN':35.8,\n",
    "            'TAIL_HEIGHT':11.76,'RANGE':3200,'CEILING':41000,'MAX_SPEED':547,'PAX_CAP':236},\n",
    "    'B739':{'MODEL':'737-900','ICAO':'B739','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'B77W':{'MODEL':'777-300ER','ICAO':'B77W','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'B38M':{'MODEL':'737 MAX 8','ICAO':'B38M','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'B737':{'MODEL':'737-700','ICAO':'B737','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'B772':{'MODEL':'777-200','ICAO':'B772','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'B744':{'MODEL':'747-400 (international, winglets)','ICAO':'B744','CLASS':'L','WAKE':'H',\n",
    "            'ENG_TYPE':'J','ENG_NUM':4},\n",
    "    'B763':{'MODEL':'767-300','ICAO':'B763','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'A319':{'MODEL':'A319','ICAO':'A319','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'IAE V2500/CFM56','ENG_MAN':'International Aero Engines/CFM International',\n",
    "            'ENG_MODEL':'IAE V2500/CFM56','ENG_THRUST':100000,'LENGTH':33.84,'WINGSPAN':35.8,\n",
    "            'TAIL_HEIGHT':11.76,'RANGE':3750,'CEILING':41000,'MAX_SPEED':547,'PAX_CAP':160},\n",
    "    'B752':{'MODEL':'757-200','ICAO':'B752','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'MD11':{'MODEL':'MD-11','ICAO':'MD11','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':3,\n",
    "           },\n",
    "    'B77L':{'MODEL':'777-200LR','ICAO':'B77L','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'A306':{'MODEL':'A-300B4-600','ICAO':'A306','CLASS':'L','WAKE':'H','ENG_TYPE':'J',\n",
    "            'ENG_NUM':2},\n",
    "    'B39M':{'MODEL':'737 MAX 9','ICAO':'B39M','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2},\n",
    "    'A318':{'MODEL':'A318','ICAO':'A318','CLASS':'L','WAKE':'M','ENG_TYPE':'J','ENG_NUM':2,\n",
    "            'ENG_NAME':'PW6000A/CFM56-5B','ENG_MAN':'Pratt & Whitney/CFM International',\n",
    "            'ENG_MODEL':'PW6000A/CFM56-5B','ENG_THRUST':106000,'LENGTH':31.44,'WINGSPAN':34.1,\n",
    "            'TAIL_HEIGHT':12.56,'RANGE':3100,'CEILING':41000,'MAX_SPEED':470,'PAX_CAP':136},\n",
    "    'A388':{'MODEL':'A380','ICAO':'A388','CLASS':'L','WAKE':'S','ENG_TYPE':'J','ENG_NUM':4,\n",
    "            'ENG_NAME':'RR Trent 900/EA GP7000','ENG_MAN':'Rolls-Royce/Engine Alliance',\n",
    "            'ENG_MODEL':'Trent 900/GP7000','ENG_THRUST':311000,'LENGTH':72.72,'WINGSPAN':79.75,\n",
    "            'TAIL_HEIGHT':24.09,'RANGE':8200,'CEILING':43000,'MAX_SPEED':551,'PAX_CAP':868},\n",
    "    'B748':{'MODEL':'747-8','ICAO':'B748','CLASS':'L','WAKE':'H','ENG_TYPE':'J','ENG_NUM':4}}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame for easier feature engineering\n",
    "aircraft_df = pd.DataFrame.from_dict(aircraft_type_dict, orient='index')\n",
    "\n",
    "# Rename ICAO column to match flight datasets\n",
    "aircraft_df = aircraft_df.rename(columns={'ICAO':'aircraft_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4be00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get codes of aircrafts available in the openap library\n",
    "avaiable_aircraft = prop.available_aircraft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a56dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Extract OpenAP Aircraft & Engine Properties as Feature Dictionary\n",
    "# ---------------------------------------------------------------\n",
    "# This function retrieves detailed aircraft and engine characteristics\n",
    "# from the OpenAP library for a given ICAO code. It produces a flattened\n",
    "# dictionary suitable for feature engineering in fuel prediction.\n",
    "#\n",
    "# Parameters:\n",
    "#   icao_code (str) : ICAO aircraft type code (e.g., 'B744', 'A320')\n",
    "#\n",
    "# Returns:\n",
    "#   dict : Flattened dictionary containing:\n",
    "#       - Aircraft-level properties (mass, wing, fuselage, drag, etc.)\n",
    "#       - Engine-level properties, prefixed with 'eng_'\n",
    "#\n",
    "# Notes:\n",
    "#   - Aircraft synonyms are automatically resolved using `use_synonym=True`.\n",
    "#   - Nested dictionaries are flattened for easier integration into a\n",
    "#     pandas DataFrame.\n",
    "#   - The default engine of the aircraft (`engine_default`) is used.\n",
    "# ================================================================\n",
    "\n",
    "def get_openap_xtics(icao_code):\n",
    "    # Retrieve aircraft properties from OpenAP\n",
    "    prop_dict = prop.aircraft(icao_code, use_synonym=True)\n",
    "    \n",
    "    # Flatten nested aircraft property dictionaries\n",
    "    breakdown_dict = {}\n",
    "    for k, v in prop_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for kk, vv in v.items():\n",
    "                if kk != 'options':  # Exclude optional subfields\n",
    "                    breakdown_dict[f'{k}_{kk}'] = vv\n",
    "        else:\n",
    "            breakdown_dict[k] = v\n",
    "\n",
    "    # Retrieve and flatten default engine properties\n",
    "    engine_dict = prop.engine(breakdown_dict['engine_default'])\n",
    "    for k, v in engine_dict.items():\n",
    "        breakdown_dict[f'eng_{k}'] = v\n",
    "\n",
    "    return breakdown_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af55f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Generate OpenAP Aircraft Feature Dictionaries for All Aircraft Types\n",
    "# ---------------------------------------------------------------\n",
    "# For each aircraft type in `aircraft_df`, retrieve its OpenAP properties\n",
    "# using `get_openap_xtics()`. These properties will be used as features\n",
    "# for fuel consumption modeling.\n",
    "#\n",
    "# Logic:\n",
    "#   - If the lowercase ICAO code is not in `avaiable_aircraft`, it means\n",
    "#     OpenAP resolved the type using a synonym. Mark `synonym = 1`.\n",
    "#   - Otherwise, mark `synonym = 0`.\n",
    "#   - Append the resulting dictionary to `openap_xtics_dict`.\n",
    "#\n",
    "# Each dictionary contains:\n",
    "#   • Flattened aircraft properties\n",
    "#   • Flattened engine properties (prefixed with 'eng_')\n",
    "#   • 'aircraft_type' and 'synonym' flags\n",
    "# ================================================================\n",
    "\n",
    "openap_xtics_dict = []\n",
    "\n",
    "for airc_typ in aircraft_df['aircraft_type'].unique():\n",
    "    xtics = get_openap_xtics(airc_typ)\n",
    "    xtics['aircraft_type'] = airc_typ\n",
    "    \n",
    "    # Flag whether OpenAP used a synonym to resolve this aircraft type\n",
    "    if airc_typ.lower() not in avaiable_aircraft:\n",
    "        xtics['synonym'] = 1\n",
    "    else:\n",
    "        xtics['synonym'] = 0\n",
    "    \n",
    "    openap_xtics_dict.append(xtics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a42095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert extracted details from dictionary to dataframe\n",
    "openap_prop_df = pd.DataFrame(openap_xtics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67fa5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each available aircraft in the train,rank and final datasets to the closest aircraft\n",
    "# available in the acropole model\n",
    "acropole_synonym = {\n",
    "    # Airbus A320 Family (Matches within the destination list)\n",
    "    'A318': 'A318',\n",
    "    'A319': 'A319',\n",
    "    'A320': 'A320',\n",
    "    'A321': 'A321',\n",
    "    'A20N': 'A320', # A320neo (maps to A320 predecessor)\n",
    "    'A21N': 'A321', # A321neo (maps to A321 predecessor)\n",
    "\n",
    "    # Boeing 737 Family (Matches within the destination list)\n",
    "    'B734': 'B734',\n",
    "    'B737': 'B737',\n",
    "    'B738': 'B738',\n",
    "    'B739': 'B739',\n",
    "    'B38M': 'B738', # 737 MAX 8 (maps to 737-800 predecessor)\n",
    "    'B39M': 'B739', # 737 MAX 9 (maps to 737-900 predecessor)\n",
    "\n",
    "    # Airbus Wide-body (Matches within the destination list)\n",
    "    'A332': 'A332',\n",
    "    'A333': 'A333',\n",
    "    \n",
    "    # Boeing Wide-body (Matches within the destination list)\n",
    "    'B763': 'B763',\n",
    "\n",
    "    # Regional/Misc. Jets (Matches within the destination list)\n",
    "    'CRJ9': 'CRJ9',\n",
    "    'E170': 'E170',\n",
    "    'E190': 'E190',\n",
    "    'E195': 'E195',\n",
    "    'E75L': 'E75L',\n",
    "    'B752': 'B752', # Mid-size narrowbody, no direct match in the list, but B752 is valid\n",
    "\n",
    "    # Turboprops (Matches within the destination list)\n",
    "    'AT72': 'AT72',\n",
    "    'AT75': 'AT75',\n",
    "    'AT76': 'AT76',\n",
    "\n",
    "    # Aircraft not in the destination list, matched to closest available alternative:\n",
    "    'B788': 'A332', # Boeing 787-8 (modern widebody, nearest match in list is A330-200 role)\n",
    "    'B789': 'A333', # Boeing 787-9 (modern widebody, nearest match in list is A330-300 role)\n",
    "    'A359': 'A333', # Airbus A350-900 (modern widebody, nearest match in list is A330-300 role)\n",
    "    'B77W': 'A333', # Boeing 777-300ER (large widebody, nearest match in list is A330-300 role)\n",
    "    'B772': 'A332', # Boeing 777-200 (widebody, nearest match in list is A330-200 role)\n",
    "    'B77L': 'A332', # Boeing 777-200LR (widebody, nearest match in list is A330-200 role)\n",
    "    'A306': 'A332', # Airbus A300-600 (older widebody, nearest match in list is A330-200 role)\n",
    "    'MD11': 'A333', # McDonnell Douglas MD-11 (widebody, nearest match in list is A330-300 role)\n",
    "    'B744': 'A333', # Boeing 747-400 (very large widebody, general widebody match)\n",
    "    'B748': 'A333', # Boeing 747-8 (very large widebody, general widebody match)\n",
    "    'A388': 'A333', # Airbus A380 (massive widebody, general widebody match)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e1498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8921eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Load and Clean FAA Aircraft Data\n",
    "# ---------------------------------------------------------------\n",
    "# The FAA Aircraft Characteristics Database provides detailed\n",
    "# specifications for many aircraft types. This dataset can supplement\n",
    "# OpenAP data with additional features relevant for fuel modeling.\n",
    "#\n",
    "# Source:\n",
    "#   • FAA Aircraft Characteristics Database\n",
    "#     https://www.faa.gov/airports/engineering/aircraft_char_database/\n",
    "#\n",
    "# Steps:\n",
    "# 1. Read the 'ACD_Data' sheet from the FAA Excel file.\n",
    "# 2. Drop columns considered unuseful for our modeling:\n",
    "#       - 'FAA_Designator', 'Model_FAA', 'Model_BADA'\n",
    "# 3. Remove the last 20 columns (assumed to be irrelevant metadata).\n",
    "# 4. Rename the ICAO code column to `aircraft_type` for consistency with\n",
    "#    other datasets.\n",
    "# ================================================================\n",
    "\n",
    "more_aircraft_data = pd.read_excel(FAA_AIRCRAFT_DATA, sheet_name='ACD_Data')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "madc_drop_cols = ['FAA_Designator', 'Model_FAA', 'Model_BADA']\n",
    "more_aircraft_data_cl = more_aircraft_data.iloc[:, :-20].drop(columns=madc_drop_cols)\n",
    "\n",
    "# Rename ICAO code column for consistency\n",
    "more_aircraft_data_cl = more_aircraft_data_cl.rename(columns={'ICAO_Code': 'aircraft_type'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b1c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Merge Aircraft Data Sources into a Comprehensive Dataset\n",
    "# ---------------------------------------------------------------\n",
    "# To create a single, enriched aircraft specification table, we merge:\n",
    "#   1. `aircraft_df`           : basic aircraft info (model, ICAO, engines)\n",
    "#   2. `more_aircraft_data_cl` : FAA data with additional technical parameters\n",
    "#   3. `openap_prop_df`        : OpenAP aircraft properties (drag, thrust, etc.)\n",
    "#\n",
    "# Additional processing:\n",
    "#   - Compute the `wingspan` column:\n",
    "#       • Use 'Wingspan_ft_without_winglets_sharklets' when available\n",
    "#       • Otherwise, fall back to 'Wingspan_ft_with_winglets_sharklets'\n",
    "#\n",
    "# The resulting `full_aircraft_data` contains comprehensive specifications\n",
    "# suitable for feature engineering in fuel prediction models.\n",
    "# ================================================================\n",
    "\n",
    "# Merge basic aircraft info with cleaned FAA data\n",
    "full_aircraft_data = pd.merge(\n",
    "    aircraft_df,\n",
    "    more_aircraft_data_cl,\n",
    "    on='aircraft_type',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill wingspan using preferred measurement\n",
    "full_aircraft_data['wingspan'] = np.where(\n",
    "    full_aircraft_data['Wingspan_ft_without_winglets_sharklets'].isna(),\n",
    "    full_aircraft_data['Wingspan_ft_with_winglets_sharklets'],\n",
    "    full_aircraft_data['Wingspan_ft_without_winglets_sharklets']\n",
    ")\n",
    "\n",
    "# Merge in OpenAP properties\n",
    "full_aircraft_data = pd.merge(\n",
    "    full_aircraft_data,\n",
    "    openap_prop_df,\n",
    "    on='aircraft_type',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ac0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# furthere clean data leaving out data already captured\n",
    "redundant_cols = ['CLASS','ENG_TYPE','ENG_NUM','LENGTH','WINGSPAN',\n",
    "                  'Wingspan_ft_without_winglets_sharklets',\n",
    "                  'Wingspan_ft_with_winglets_sharklets','TAIL_HEIGHT']\n",
    "full_aircraft_data = full_aircraft_data.drop(columns=redundant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1513637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Enrich Flight Lists with Full Aircraft Specifications\n",
    "# ---------------------------------------------------------------\n",
    "# Merge the comprehensive aircraft dataset (`full_aircraft_data`) with\n",
    "# each flight list to attach detailed aircraft characteristics to each\n",
    "# flight\n",
    "#\n",
    "# The merge is performed on `aircraft_type` for all datasets:\n",
    "#   - Training flights (`train_flightlist`)\n",
    "#   - Ranking/validation flights (`rank_flightlist`)\n",
    "#   - Final submission flights (`final_flightlist`)\n",
    "# ================================================================\n",
    "train_flightlist = pd.merge(train_flightlist,full_aircraft_data,on='aircraft_type',how='left')\n",
    "rank_flightlist = pd.merge(rank_flightlist,full_aircraft_data,on='aircraft_type',how='left')\n",
    "final_flightlist = pd.merge(final_flightlist,full_aircraft_data,on='aircraft_type',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "264a95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Compute the Haversine Distance Between Two Geographic Points\n",
    "# ---------------------------------------------------------------\n",
    "# The Haversine formula calculates the great-circle distance between\n",
    "# two points on a sphere (Earth) given their latitude and longitude.\n",
    "# This is useful for estimating straight-line distances between\n",
    "# airports or waypoints.\n",
    "#\n",
    "# Parameters:\n",
    "#   lat_lon1 : tuple or list of (latitude, longitude) in degrees\n",
    "#   lat_lon2 : tuple or list of (latitude, longitude) in degrees\n",
    "#\n",
    "# Returns:\n",
    "#   float : distance between the two points in meters\n",
    "#\n",
    "# Notes:\n",
    "#   - The Earth's radius is assumed to be 6371 km.\n",
    "#   - Inputs are converted from degrees to radians before computation.\n",
    "# ================================================================\n",
    "\n",
    "def haversine(lat_lon1, lat_lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1 = map(np.radians, lat_lon1)\n",
    "    lat2, lon2 = map(np.radians, lat_lon2)\n",
    "    \n",
    "    # Haversine formula components\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    # Distance in meters\n",
    "    return R * c * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01f70dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Compute Total Duration per Flight Phase\n",
    "# ---------------------------------------------------------------\n",
    "# This function calculates the total time spent in each flight phase\n",
    "# (e.g., takeoff, climb, cruise, descent, landing) for a given flight\n",
    "# DataFrame.\n",
    "#\n",
    "# Parameters:\n",
    "#   ndf   : pandas.DataFrame\n",
    "#           Flight-level time series containing at least:\n",
    "#             - 'timestamp' column (datetime)\n",
    "#             - Column specifying the flight phase (categorical)\n",
    "#   phase : str\n",
    "#           Name of the column representing flight phases\n",
    "#\n",
    "# Returns:\n",
    "#   dict : mapping of {phase_category : total_duration_in_seconds}\n",
    "#\n",
    "# Methodology:\n",
    "#   1. Identify contiguous blocks of the same flight phase.\n",
    "#   2. For each block, calculate duration as the difference between\n",
    "#      last and first timestamp.\n",
    "#   3. Aggregate durations per phase category.\n",
    "# ================================================================\n",
    "\n",
    "def get_phase_duration(ndf, phase):\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df = ndf.copy()\n",
    "    \n",
    "    # Identify contiguous groups where the phase value changes\n",
    "    df['group'] = (df[phase] != df[phase].shift()).cumsum()\n",
    "    \n",
    "    # Compute start and end timestamps per group\n",
    "    group_durations = (\n",
    "        df.groupby([phase, 'group'])['timestamp']\n",
    "          .agg(['first', 'last'])\n",
    "    )\n",
    "    \n",
    "    # Compute duration (in seconds) per group\n",
    "    group_durations['duration'] = (group_durations['last'] - group_durations['first']).dt.total_seconds()\n",
    "    \n",
    "    # Sum durations across all groups for each phase\n",
    "    result = group_durations.groupby(phase)['duration'].sum().to_dict()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b82ac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Retrieve Flight Metadata by Flight ID\n",
    "# ---------------------------------------------------------------\n",
    "# This function searches for a flight's metadata across all flight\n",
    "# datasets (training, ranking/validation, and final submission)\n",
    "# and returns the corresponding row(s) as a DataFrame.\n",
    "#\n",
    "# Parameters:\n",
    "#   flight_id : str\n",
    "#       Unique identifier of the flight to retrieve.\n",
    "#\n",
    "# Returns:\n",
    "#   pandas.DataFrame : flight metadata including:\n",
    "#       - origin and destination airports\n",
    "#       - takeoff and landing times\n",
    "#       - aircraft type and associated features\n",
    "#       - airport coordinates and elevations\n",
    "#\n",
    "# Notes:\n",
    "#   - Searches datasets in the order: train_flightlist → rank_flightlist → final_flightlist\n",
    "#   - Returns an empty DataFrame if the flight ID is not found.\n",
    "# ================================================================\n",
    "\n",
    "def get_flight_metadata(flight_id):\n",
    "    # Attempt to locate the flight in the training dataset\n",
    "    fl = train_flightlist[train_flightlist.flight_id == flight_id]\n",
    "    \n",
    "    # If not found, search in the ranking/validation dataset\n",
    "    if fl.empty:\n",
    "        fl = rank_flightlist[rank_flightlist.flight_id == flight_id]\n",
    "    \n",
    "    # If still not found, search in the final submission dataset\n",
    "    if fl.empty:\n",
    "        fl = final_flightlist[final_flightlist.flight_id == flight_id]\n",
    "    \n",
    "    return fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f812b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Evaluate Resampled Flight Data Quality Against Raw Observations\n",
    "# ---------------------------------------------------------------\n",
    "# This function computes metrics to assess how closely a resampled\n",
    "# flight trajectory matches the original raw timestamps.\n",
    "#\n",
    "# Parameters:\n",
    "#   raw_df      : pandas.DataFrame\n",
    "#                 Original flight trajectory with at least a 'timestamp' column\n",
    "#   resample_df : pandas.DataFrame\n",
    "#                 Resampled trajectory to be evaluated, must also contain 'timestamp'\n",
    "#\n",
    "# Returns:\n",
    "#   pandas.DataFrame : `resample_df` enriched with the following columns:\n",
    "#       - sec_from_real : distance (seconds) to the nearest raw timestamp\n",
    "#       - raw_diff_mean : mean interval of raw timestamps\n",
    "#       - raw_diff_count: number of intervals in raw timestamps\n",
    "#       - raw_diff_max  : maximum interval in raw timestamps\n",
    "#       - raw_diff_min  : minimum interval in raw timestamps\n",
    "#       - raw_diff_std  : standard deviation of intervals\n",
    "#       - auth_score    : exponential decay score reflecting proximity to real timestamps\n",
    "#\n",
    "# Methodology:\n",
    "#   1. Convert timestamps to UTC datetime.\n",
    "#   2. Compute intervals between consecutive raw timestamps.\n",
    "#   3. For each resampled timestamp, calculate the distance in seconds\n",
    "#      to the nearest raw timestamp.\n",
    "#   4. Compute summary statistics of raw timestamp intervals.\n",
    "#   5. Compute an \"authenticity score\" using exponential decay with\n",
    "#      a half-life of 60 seconds (closer timestamps get higher score).\n",
    "# ================================================================\n",
    "\n",
    "def compute_resample_quality(raw_df, resample_df):\n",
    "    # Ensure timestamps are in datetime format with UTC\n",
    "    raw_df['timestamp'] = pd.to_datetime(raw_df['timestamp'], utc=True)\n",
    "    resample_df['timestamp'] = pd.to_datetime(resample_df['timestamp'], utc=True)\n",
    "\n",
    "    # Compute intervals between consecutive raw timestamps (in seconds)\n",
    "    raw_interval = raw_df['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "    # Convert timestamps to integer seconds since epoch\n",
    "    real_times = raw_df['timestamp'].astype(\"int64\").to_numpy() // 1_000_000_000\n",
    "    resampled_times = resample_df['timestamp'].astype(\"int64\").to_numpy() // 1_000_000_000\n",
    "\n",
    "    # Compute distance to nearest raw timestamp for each resampled point\n",
    "    dist = np.abs(resampled_times[:, None] - real_times[None, :]).min(axis=1)\n",
    "    resample_df['sec_from_real'] = dist\n",
    "\n",
    "    # Attach summary statistics of raw intervals\n",
    "    resample_df['raw_diff_mean'] = np.mean(raw_interval)\n",
    "    resample_df['raw_diff_count'] = np.size(raw_interval)\n",
    "    resample_df['raw_diff_max'] = np.max(raw_interval)\n",
    "    resample_df['raw_diff_min'] = np.min(raw_interval)\n",
    "    resample_df['raw_diff_std'] = np.std(raw_interval)\n",
    "\n",
    "    # Compute authenticity score based on exponential decay\n",
    "    lam = 1 / 60  # half-life of 60 seconds\n",
    "    resample_df['auth_score'] = np.exp(-lam * resample_df['sec_from_real'])\n",
    "\n",
    "    return resample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15741bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Smooth ATM Phase Classification for a Flight\n",
    "# ---------------------------------------------------------------\n",
    "# Assigns ATM (Air Traffic Management) phases to flight trajectory\n",
    "# points based on distance from departure and arrival airports.\n",
    "#\n",
    "# Rules:\n",
    "#   - All points before the last 'DEP' phase are set to 'DEP'\n",
    "#   - All points after the first 'ARR' phase are set to 'ARR'\n",
    "#   - Remaining points default to 'ENR' (Enroute)\n",
    "#\n",
    "# Parameters:\n",
    "#   flight_df : pandas.DataFrame\n",
    "#       Flight trajectory data, must include columns:\n",
    "#         - 'timestamp'       : datetime of observation\n",
    "#         - 'dist_from_adep'  : distance to departure airport (NM or km)\n",
    "#         - 'dist_from_ades'  : distance to destination airport (NM or km)\n",
    "#\n",
    "# Returns:\n",
    "#   pandas.DataFrame : sorted flight_df with smoothed 'atm_phase' column\n",
    "#\n",
    "# Notes:\n",
    "#   - The function sorts by timestamp internally to ensure chronological ordering.\n",
    "#   - Phases are first assigned based on distance thresholds:\n",
    "#       • <40 units from departure airport → 'DEP'\n",
    "#       • <100 units from arrival airport → 'ARR'\n",
    "#   - Then smoothing rules are applied to ensure logical continuity.\n",
    "# ================================================================\n",
    "\n",
    "def get_atm_phases(flight_df):\n",
    "    # Initialize all phases as Enroute (ENR)\n",
    "    flight_df['atm_phase'] = 'ENR'\n",
    "    \n",
    "    # Assign preliminary DEP and ARR phases based on distance thresholds\n",
    "    flight_df.loc[flight_df['dist_from_adep'] < 40, 'atm_phase'] = 'DEP'\n",
    "    flight_df.loc[flight_df['dist_from_ades'] < 100, 'atm_phase'] = 'ARR'\n",
    "\n",
    "    # Ensure correct chronological order\n",
    "    df = flight_df.sort_values('timestamp', ignore_index=True).copy()\n",
    "    \n",
    "    # Find indices of last DEP and first ARR\n",
    "    dep_indices = df.index[df['atm_phase'] == 'DEP']\n",
    "    arr_indices = df.index[df['atm_phase'] == 'ARR']\n",
    "\n",
    "    last_dep_idx = dep_indices.max() if len(dep_indices) > 0 else None\n",
    "    first_arr_idx = arr_indices.min() if len(arr_indices) > 0 else None\n",
    "\n",
    "    # Apply smoothing rules to enforce phase continuity\n",
    "    if last_dep_idx is not None:\n",
    "        df.loc[:last_dep_idx, 'atm_phase'] = 'DEP'\n",
    "\n",
    "    if first_arr_idx is not None:\n",
    "        df.loc[first_arr_idx:, 'atm_phase'] = 'ARR'\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ada268a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flight_segments_final(train_fuel, flights_dir=TRAIN_FLIGHTS_DIR,\n",
    "                                  ts_cols=None):\n",
    "    if ts_cols is None:\n",
    "        ts_cols = [\n",
    "            'longitude','altitude','groundspeed',\n",
    "            'mach','CAS','fuel_flow','fuel',\n",
    "            'drag','thrust','auth_score','cl_fuel',\n",
    "            'enr_fuel','dist_from_ades','acp_fuel','acp_fuelflow',\n",
    "            ]\n",
    "\n",
    "    phases = ['GND','CL','DE','LVL','CR','NA']\n",
    "    atm_phases = ['DEP','ENR','ARR']\n",
    "    all_segments = []\n",
    "\n",
    "    # --- loop once per flight\n",
    "    for flight_id, flight_rows in train_fuel.groupby('flight_id'):\n",
    "        \n",
    "        #prc776443417 and prc776502511 appear to be parts of the same flight\n",
    "        if flight_id == 'prc776443417':\n",
    "            print(flight_id)\n",
    "            raw_flight_df_1 = pd.read_parquet(TRAIN_FLIGHTS_DIR / \"prc776443417.parquet\")\n",
    "            raw_flight_df_2 = pd.read_parquet(TRAIN_FLIGHTS_DIR / \"prc776502511.parquet\")\n",
    "            raw_flight_df = pd.concat([raw_flight_df_1,raw_flight_df_2])\n",
    "            raw_flight_df['flight_id'] = 'prc776443417'\n",
    "\n",
    "        # prc778592434, prc778582087, and prc778566666 also appear to be parts of the same flight\n",
    "        elif flight_id == 'prc778592434':\n",
    "            print(flight_id)\n",
    "            raw_flight_df_1 = pd.read_parquet(TRAIN_FLIGHTS_DIR / \"prc778592434.parquet\")\n",
    "            raw_flight_df_2 = pd.read_parquet(TRAIN_FLIGHTS_DIR / \"prc778582087.parquet\")\n",
    "            raw_flight_df_3 = pd.read_parquet(TRAIN_FLIGHTS_DIR / \"prc778566666.parquet\")\n",
    "            raw_flight_df = pd.concat([raw_flight_df_1,raw_flight_df_2,raw_flight_df_3])\n",
    "            raw_flight_df['flight_id'] = 'prc778592434'\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            try:\n",
    "                raw_flight_df = pd.read_parquet(flights_dir / f\"{flight_id}.parquet\")\n",
    "            except:\n",
    "                # some flights id in the final_flightlist are available in the rank trajectories dir only\n",
    "                raw_flight_df = pd.read_parquet(RANK_FLIGHTS_DIR / f\"{flight_id}.parquet\")\n",
    "            \n",
    "        \n",
    "        flight_data = get_flight_metadata(flight_id)\n",
    "        \n",
    "        \n",
    "        takeoff = pd.to_datetime(flight_data['takeoff'].item(),utc=True)\n",
    "        landed = pd.to_datetime(flight_data['landed'].item(),utc=True)\n",
    "        orig_lat = flight_data['orig_lat'].item()\n",
    "        orig_lon = flight_data['orig_long'].item()\n",
    "        dest_lat = flight_data['dest_lat'].item()\n",
    "        dest_lon = flight_data['dest_long'].item()   \n",
    "        orig_elev = flight_data['orig_elev'].item() \n",
    "        dest_elev = flight_data['dest_elev'].item()\n",
    "\n",
    "        takeoff_minute = pd.to_datetime(takeoff.floor('min'),utc=True)\n",
    "        landed_minute = pd.to_datetime(landed.ceil('min'),utc=True)\n",
    "\n",
    "        takeoff_data = flight_data[['orig_elev','orig_long',\n",
    "                                    'orig_lat','takeoff','aircraft_type',\n",
    "                                    'flight_id']].copy()\n",
    "        \n",
    "\n",
    "        if raw_flight_df['timestamp'].dt.tz is None:\n",
    "            raw_flight_df['timestamp'] = raw_flight_df['timestamp'].dt.tz_localize('UTC')\n",
    "        else:\n",
    "            raw_flight_df['timestamp'] = raw_flight_df['timestamp'].dt.tz_convert('UTC')\n",
    "        takeoff = pd.to_datetime(takeoff).tz_convert('UTC') if takeoff.tzinfo else takeoff.tz_localize('UTC')\n",
    "                \n",
    "        raw_flight_df = raw_flight_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "        #ensure all timestamps for which prediction is required are included\n",
    "        earliest_predict = pd.to_datetime(flight_rows['start'],utc=True).min().floor('min')\n",
    "        latest_predict = pd.to_datetime(flight_rows['end'],utc=True).max().ceil('min')\n",
    "\n",
    "        earliest_raw_flight_time = raw_flight_df['timestamp'].min()\n",
    "        latest_raw_flight_time = raw_flight_df['timestamp'].max()\n",
    "\n",
    "        takeoff_data = takeoff_data.rename(columns={'orig_elev':'altitude',\n",
    "                                                   'orig_long':'longitude',\n",
    "                                                   'orig_lat':'latitude',\n",
    "                                                   'takeoff':'timestamp',\n",
    "                                                   'aircraft_type':'typecode'})\n",
    "        \n",
    "\n",
    "        if (earliest_raw_flight_time<takeoff_minute) and (earliest_predict<earliest_raw_flight_time):\n",
    "            #print('prediction is required for unvavailable period with earliest available being flight trajectory data')\n",
    "            #add earliest predict before earliest rawflight\n",
    "            earliest_rawflight = raw_flight_df[raw_flight_df['timestamp']==earliest_raw_flight_time]\n",
    "            earliest_pred_data = earliest_rawflight.copy()\n",
    "            earliest_pred_data['timestamp'] = earliest_predict\n",
    "            raw_flight_df = pd.concat([earliest_pred_data,raw_flight_df])\n",
    "            #print('just added the required segment')\n",
    "            #display(raw_flight_df)\n",
    "\n",
    "        \n",
    "\n",
    "        elif (earliest_raw_flight_time>=takeoff_minute) and (earliest_predict<takeoff_minute):\n",
    "            #print('prediction is required for period with earliest available being takeoff')\n",
    "            #add earliest predict before takeoff data\n",
    "            \n",
    "            earliest_pred_data = takeoff_data.copy()\n",
    "            earliest_pred_data['timestamp'] = earliest_predict\n",
    "            raw_flight_df = pd.concat([earliest_pred_data,raw_flight_df])\n",
    "            #print('just added the required segment')\n",
    "            #display(raw_flight_df)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # if next observation in trajectory after takeoff happens within 2 minutes of takeoff,\n",
    "        # use the next observation's vertical rate for the takeoff vertical rate\n",
    "        #vertical rate value in trajectory after takeoff\n",
    "        obs_after_takeoff = raw_flight_df.loc[raw_flight_df['timestamp']>takeoff].head(1)\n",
    "        obs_after_takeoff_time = obs_after_takeoff['timestamp'].item()\n",
    "        time_within_takeoff = (obs_after_takeoff_time - takeoff).total_seconds()/60\n",
    "        if time_within_takeoff<2:\n",
    "            obs_after_takeoff_roc = obs_after_takeoff['vertical_rate'].item()\n",
    "            new_next_altitude = (obs_after_takeoff_roc*time_within_takeoff) + orig_elev\n",
    "            raw_flight_df.loc[raw_flight_df['timestamp']==obs_after_takeoff_time,'altitude']=new_next_altitude\n",
    "            takeoff_data['vertical_rate'] = obs_after_takeoff_roc\n",
    "\n",
    "        pre_append_df = raw_flight_df.copy()\n",
    "        \n",
    "        filtered_df = pre_append_df[pre_append_df['timestamp']<=takeoff].copy()\n",
    "\n",
    "        \n",
    "        #if there are observations preceding takeoff\n",
    "        if filtered_df.shape[0]>0:\n",
    "            \n",
    "            \n",
    "            raw_flight_df = pre_append_df\n",
    "\n",
    "            \n",
    "            raw_flight_df.loc[raw_flight_df['timestamp']<takeoff,'vertical_rate'] = 0\n",
    "            raw_flight_df.loc[raw_flight_df['timestamp']<takeoff,'altitude'] = orig_elev\n",
    "\n",
    "            pre_append_df = raw_flight_df.copy()\n",
    "        \n",
    "        land_data = flight_data[['dest_elev','dest_long','dest_lat',\n",
    "                                 'landed','aircraft_type','flight_id']].copy()\n",
    "        \n",
    "        \n",
    "        land_data = land_data.rename(columns={'dest_elev':'altitude',\n",
    "                                              'dest_long':'longitude',\n",
    "                                              'dest_lat':'latitude',\n",
    "                                              'landed':'timestamp',\n",
    "                                              'aircraft_type':'typecode',\n",
    "                                             'vertical_rate':0})\n",
    "        \n",
    "        if (latest_raw_flight_time>landed_minute) and (latest_predict>latest_raw_flight_time):\n",
    "            #add latest predict after latest rawflight\n",
    "            #print('prediction is required for unvavailable period with latest available being flight trajectory data')\n",
    "            latest_rawflight = raw_flight_df[raw_flight_df['timestamp']==latest_raw_flight_time]\n",
    "            latest_pred_data = latest_rawflight.copy()\n",
    "            latest_pred_data['timestamp'] = latest_predict\n",
    "            raw_flight_df = pd.concat([raw_flight_df,latest_pred_data])\n",
    "            #if raw_flight_df['timestamp'].max()< latest_predict:\n",
    "            #    print('why latest predict still absent')\n",
    "\n",
    "        \n",
    "        elif (latest_raw_flight_time<=landed_minute) and (latest_predict>landed_minute):\n",
    "            #print('prediction is required for unavailable period with latest available being landed data')\n",
    "            #add latest predict after landed data\n",
    "        \n",
    "            latest_pred_data = land_data.copy()\n",
    "            latest_pred_data['timestamp'] = latest_predict\n",
    "            raw_flight_df = pd.concat([raw_flight_df,latest_pred_data])\n",
    "            #if raw_flight_df['timestamp'].max()< latest_predict:\n",
    "            #    print('why latest predict still absent')\n",
    "            \n",
    "        \n",
    "        pre_append_df = raw_flight_df.copy()\n",
    "\n",
    "        lfiltered_df = pre_append_df[pre_append_df['timestamp']>=landed].copy()\n",
    "        if lfiltered_df.shape[0]>0:\n",
    "            \n",
    "            raw_flight_df = pre_append_df\n",
    "\n",
    "            \n",
    "            raw_flight_df.loc[raw_flight_df['timestamp']>landed,'vertical_rate'] = 0\n",
    "            raw_flight_df.loc[raw_flight_df['timestamp']>landed,'altitude'] = dest_elev\n",
    "            \n",
    "            \n",
    "            pre_append_df = raw_flight_df.copy()\n",
    "        \n",
    "        \n",
    "        land_data['timestamp'] = pd.to_datetime(land_data['timestamp'],utc=True)\n",
    "        takeoff_data['timestamp'] = pd.to_datetime(takeoff_data['timestamp'],utc=True)\n",
    "        raw_flight_df = pd.concat([takeoff_data,raw_flight_df,land_data],axis=0).sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "\n",
    "        \n",
    "        res_flight_df = Traffic(raw_flight_df).filter().resample('60s').eval().data\n",
    "        \n",
    "        res_flight_df.loc[res_flight_df['timestamp']<takeoff_minute,'vertical_rate'] = 0\n",
    "        res_flight_df.loc[res_flight_df['timestamp']>landed_minute,'vertical_rate'] = 0\n",
    "\n",
    "        res_flight_df.loc[res_flight_df['timestamp']<=takeoff_minute,'altitude'] = orig_elev\n",
    "        res_flight_df.loc[res_flight_df['timestamp']>=landed_minute,'altitude'] = dest_elev\n",
    "\n",
    "\n",
    "        \n",
    "        flight_df = compute_resample_quality(raw_flight_df.copy(),res_flight_df)\n",
    "        fl_max = flight_df['altitude'].max()\n",
    "        \n",
    "        \n",
    "            \n",
    "        flight_df = flight_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "        #get NM distance from departing airport\n",
    "        flight_df['dist_from_adep'] = flight_df.apply(\n",
    "            lambda r: haversine((r.latitude,r.longitude),\n",
    "                                (orig_lat,orig_lon)),axis=1)\n",
    "        flight_df['dist_from_ades'] = flight_df.apply(\n",
    "            lambda r: haversine((r.latitude,r.longitude),\n",
    "                                (dest_lat,dest_lon)),axis=1)\n",
    "        flight_df['dist_from_ades'] = flight_df['dist_from_ades']/1852\n",
    "        flight_df['dist_from_adep'] = flight_df['dist_from_adep']/1852\n",
    "\n",
    "        flight_df = get_atm_phases(flight_df)\n",
    "        \n",
    "        flight_start = flight_df['timestamp'].min()\n",
    "        flight_end = flight_df['timestamp'].max()\n",
    "        \n",
    "        # Precompute arrays\n",
    "        ts = (flight_df.timestamp - flight_start).dt.total_seconds().to_numpy()\n",
    "        alt = flight_df['altitude'].to_numpy()\n",
    "        \n",
    "        times = flight_df['timestamp'].to_numpy()\n",
    "        tas = flight_df['TAS'].fillna(flight_df['CAS']).fillna(flight_df['groundspeed']).to_numpy()\n",
    "        roc = flight_df['vertical_rate'].to_numpy()\n",
    "\n",
    "        typecode = flight_df['typecode'].dropna().unique()[0]\n",
    "        fe = FuelEstimator()\n",
    "        \n",
    "\n",
    "        acpe_typecode = acropole_synonym[typecode.upper()]\n",
    "        acpe_flight = flight_df.copy()\n",
    "        acpe_flight['ts'] = ts\n",
    "        acpe_flight['tas_filled'] = tas\n",
    "        acpe_flight['type_mapped'] = acpe_typecode\n",
    "        flight_fuel = fe.estimate(\n",
    "            acpe_flight,typecode=\"type_mapped\",groundspeed=\"groundspeed\",\n",
    "            altitude=\"altitude\",vertical_rate=\"vertical_rate\",second=\"ts\",\n",
    "            airspeed=\"tas_filled\",)\n",
    "\n",
    "        flight_fuel['inst_fuel'] = flight_fuel['fuel_cumsum'].diff()\n",
    "        flight_fuel['inst_fuel'] = flight_fuel['inst_fuel'].fillna(flight_fuel['fuel_cumsum'].iloc[0])\n",
    "\n",
    "        flight_df['acp_fuel'] = flight_fuel['inst_fuel']\n",
    "        flight_df['acp_fuelflow'] = flight_fuel['fuel_flow']\n",
    "        \n",
    "        acp_fuelflow = flight_df['acp_fuelflow'].to_numpy()\n",
    "\n",
    "        \n",
    "        # --- Phase labeling\n",
    "        fp = FlightPhase()\n",
    "        fp.set_trajectory(ts, alt, tas, roc)\n",
    "        flight_df['phase'] = fp.phaselabel()\n",
    "\n",
    "        #enforce ground phases\n",
    "        flight_df.loc[flight_df['timestamp']>landed_minute,'phase'] = 'GND'\n",
    "        flight_df.loc[flight_df['timestamp']<takeoff_minute,'phase'] = 'GND'\n",
    "              \n",
    "               \n",
    "        fphases = flight_df['phase'].to_numpy()\n",
    "        atmphases = flight_df['atm_phase'].to_numpy()\n",
    "\n",
    "        # Phase counts and durations (with defaults)\n",
    "        flight_phase_counts = flight_df['phase'].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        \n",
    "        for k in phases:\n",
    "            flight_phase_counts.setdefault(k, 0)\n",
    "            \n",
    "        flight_phase_counts = {f'flight_{k}_ct': v for k, v in flight_phase_counts.items()}\n",
    "        \n",
    "        \n",
    "        # --- Fuel flow computation (vectorized per-row loop)\n",
    "        mtow = openap_prop_df.loc[\n",
    "            openap_prop_df['aircraft_type'] == typecode, 'mtow'\n",
    "        ].item()\n",
    "\n",
    "        \n",
    "        fuelflow = FuelFlow(typecode, use_synonym=True)\n",
    "        dragobj = Drag(ac=typecode,use_synonym=True)\n",
    "        thrustobj = Thrust(ac=typecode,use_synonym=True)\n",
    "        \n",
    "        \n",
    "        # Compute time deltas (seconds)\n",
    "        \n",
    "        d_ts = flight_df['timestamp'].diff().dt.total_seconds().bfill()\n",
    "\n",
    "        fuelflow_every_step = []\n",
    "        fuel_every_step = []\n",
    "        drag_every_step = []\n",
    "        thrust_every_step = []\n",
    "        \n",
    "        mass_current = mtow\n",
    "        for i in range(flight_df.shape[0]):\n",
    "            drag = dragobj.clean(mass=mass_current, tas=tas[i],\n",
    "                                 alt=alt[i], vs=roc[i])\n",
    "            if fphases[i] in ['CR']:\n",
    "                thrust = thrustobj.cruise(alt=alt[i],tas=tas[i])\n",
    "            elif fphases[i] in ['LVL','NA']:\n",
    "                if (atmphases[i]=='DEP') and (times[i]>takeoff):\n",
    "                    thrust = thrustobj.climb(alt=alt[i],tas=tas[i],roc=roc[i])\n",
    "                elif atmphases[i]=='ENR':\n",
    "                    thrust = thrustobj.cruise(alt=alt[i],tas=tas[i])\n",
    "                elif (atmphases[i]=='ARR') and (times[i]<landed):\n",
    "                    thrust = thrustobj.descent_idle(tas=tas[i], alt=alt[i])\n",
    "                else:\n",
    "                    thrust = np.nan\n",
    "            elif fphases[i]=='CL':\n",
    "                thrust = thrustobj.climb(alt=alt[i],tas=tas[i],roc=roc[i])\n",
    "            elif fphases[i]=='DE':\n",
    "                thrust = thrustobj.descent_idle(tas=tas[i], alt=alt[i])\n",
    "            else:\n",
    "                thrust = np.nan\n",
    "\n",
    "            \n",
    "            drag_every_step.append(drag)\n",
    "            thrust_every_step.append(thrust)\n",
    "            ff = fuelflow.enroute(\n",
    "                mass=mass_current,\n",
    "                tas=tas[i],\n",
    "                alt=alt[i],\n",
    "                vs=roc[i],\n",
    "                )\n",
    "            if np.isnan(ff):\n",
    "                ff = acp_fuelflow[i]\n",
    "\n",
    "            if np.isnan(ff):\n",
    "                candidates = [\n",
    "                    v for v, p, a in zip(fuelflow_every_step[:i], fphases[:i], alt[:i])\n",
    "                    if (not np.isnan(v)) and (p == fphases[i]) and abs(a-alt[i]) < 1500\n",
    "                ]\n",
    "                if candidates:\n",
    "                    ff = np.nanmedian(candidates)\n",
    "                candidates2 = [\n",
    "                    v for v, p in zip(fuelflow_every_step[:i], fphases[:i])\n",
    "                    if (not np.isnan(v)) and (p == fphases[i])\n",
    "                ]\n",
    "                if candidates2 and np.isnan(ff):\n",
    "                    ff = np.nanmedian(candidates2)\n",
    "                    \n",
    "                if np.isnan(ff):\n",
    "                    ff = np.nanmedian(fuelflow_every_step)\n",
    "            \n",
    "            fuel = ff * d_ts[i]\n",
    "            \n",
    "            \n",
    "            fuelflow_every_step.append(ff)\n",
    "            fuel_every_step.append(fuel)\n",
    "            if np.isnan(fuel):\n",
    "                pass\n",
    "            else:\n",
    "                mass_current -= fuel\n",
    "\n",
    "        atmphase_lists = {p: [] for p in ['DEP','ENR','ARR']}\n",
    "        \n",
    "        phase_lists = {p: [] for p in ['CR','CL','LVL','DE','NA','GND']}\n",
    "\n",
    "        for ph, fuel in zip(fphases, fuel_every_step):\n",
    "            for p in phase_lists:\n",
    "                phase_lists[p].append(fuel if ph == p else 0)\n",
    "\n",
    "        cr_fuel  = phase_lists['CR']\n",
    "        cl_fuel  = phase_lists['CL']\n",
    "        lvl_fuel = phase_lists['LVL']\n",
    "        de_fuel  = phase_lists['DE']\n",
    "        na_fuel  = phase_lists['NA']\n",
    "        gnd_fuel = phase_lists['GND']\n",
    "\n",
    "        for aph, fuel in zip(atmphases, fuel_every_step):\n",
    "            for p in atmphase_lists:\n",
    "                atmphase_lists[p].append(fuel if aph == p else 0)        \n",
    "        \n",
    "        dep_fuel  = atmphase_lists['DEP']\n",
    "        enr_fuel  = atmphase_lists['ENR']\n",
    "        arr_fuel = atmphase_lists['ARR']\n",
    "        \n",
    "        flight_df = flight_df.assign(fuel_flow=fuelflow_every_step,cl_fuel=cl_fuel,\n",
    "                                     fuel=fuel_every_step,gnd_fuel=gnd_fuel,\n",
    "                                    drag = drag_every_step,cr_fuel=cr_fuel,\n",
    "                                    thrust = thrust_every_step,lvl_fuel=lvl_fuel,\n",
    "                                    na_fuel=na_fuel,de_fuel=de_fuel,\n",
    "                                    dep_fuel=dep_fuel,enr_fuel=enr_fuel,\n",
    "                                     arr_fuel=arr_fuel,d_ts=d_ts)\n",
    "        \n",
    "        \n",
    "        # fill gnd thrust with minimum idle thrust\n",
    "        flight_df.loc[\n",
    "            (flight_df['thrust'].isna()) & (flight_df['phase'] == 'GND'),\n",
    "            'thrust'\n",
    "        ] = flight_df.loc[flight_df['phase'] == 'DE', 'thrust'].min() / 2\n",
    "        \n",
    "        # fill gnd fuelflow with minimum fuelflow\n",
    "        flight_df.loc[\n",
    "            (flight_df['fuel_flow'].isna()) & (flight_df['phase'] == 'GND'),\n",
    "            'fuel_flow'\n",
    "        ] = flight_df.loc[flight_df['phase'] == 'DE', 'fuel_flow'].min() / 2\n",
    "\n",
    "        #fill na thrust at cl and departure with max thrust\n",
    "        flight_df.loc[\n",
    "            (flight_df['thrust'].isna()) & (flight_df['phase'] == 'CL') & (flight_df['atm_phase']=='DEP'),\n",
    "            'thrust'\n",
    "        ] = flight_df.loc[flight_df['phase'] == 'CL', 'thrust'].max()\n",
    "\n",
    "        #fill na fuelflow at CL and DEP phase with max fuel flow\n",
    "        flight_df.loc[\n",
    "            (flight_df['fuel_flow'].isna()) & (flight_df['phase'] == 'CL') & (flight_df['atm_phase']=='DEP'),\n",
    "            'fuel_flow'\n",
    "        ] = flight_df.loc[flight_df['phase'] == 'CL', 'fuel_flow'].max()\n",
    "        \n",
    "        \n",
    "\n",
    "        #fill gnd fuel fom assumed fuel_flow\n",
    "        flight_df['fuel'] = flight_df['fuel_flow'] * flight_df['d_ts']\n",
    "\n",
    "        flight_df.drop(columns=['d_ts'],inplace=True)\n",
    "        \n",
    "        total_flight_fuel = np.nan if flight_df['fuel'].sum()==0 else flight_df['fuel'].sum()\n",
    "        \n",
    "        \n",
    "        ts_array = flight_df['timestamp'].to_numpy()\n",
    "        raw_ts = raw_flight_df['timestamp'].to_numpy()\n",
    "        \n",
    "        # --- Process each fuel segment\n",
    "        for _, row in flight_rows.iterrows():\n",
    "            start, end = pd.to_datetime(row['start'],\n",
    "                                        utc=True), pd.to_datetime(row['end'],\n",
    "                                                                  utc=True)\n",
    "            \n",
    "            mask = (ts_array >= start) & (ts_array <= end)\n",
    "            seg = flight_df.loc[mask]\n",
    "            raw_mask = (raw_ts >= start) & (raw_ts <= end)\n",
    "            raw_seg_df = raw_flight_df[raw_mask]\n",
    "\n",
    "            #some segments needed for prediction turned out to require for less than 1 minute:\n",
    "            if (start-end).total_seconds()<60 and seg.empty:\n",
    "                mask = (ts_array >= start) & (ts_array <= end.ceil('min'))\n",
    "                seg = flight_df.loc[mask]\n",
    "                raw_mask = (raw_ts >= start) & (raw_ts <= end.ceil('min'))\n",
    "                raw_seg_df = raw_flight_df[raw_mask]\n",
    "\n",
    "                if seg.empty:\n",
    "                    mask = (ts_array >= start.floor('min')) & (ts_array <= end)\n",
    "                    seg = flight_df.loc[mask]\n",
    "                    raw_mask = (raw_ts >= start.floor('min')) & (raw_ts <= end)\n",
    "                    raw_seg_df = raw_flight_df[raw_mask]\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            raw_seg_interval = raw_seg_df['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "            seg_scalars = {\n",
    "                'seg_start': start,\n",
    "                'seg_end': end,\n",
    "                'flight_id': flight_id,\n",
    "                'fuel_kg': row['fuel_kg'],\n",
    "                'flight_fuel':total_flight_fuel,\n",
    "                'flight_start':flight_start,\n",
    "                'flight_end': flight_end,\n",
    "                'real_flight_dur':(flight_end-flight_start).total_seconds(),\n",
    "                'fl_max_alti': fl_max\n",
    "            }\n",
    "            \n",
    "            seg_scalars['rawseg_diff_count'] = np.size(raw_seg_interval)\n",
    "            seg_scalars['rawseg_diff_mean'] = np.mean(raw_seg_interval) if seg_scalars['rawseg_diff_count']>0 else np.nan\n",
    "            \n",
    "            \n",
    "\n",
    "            if seg.empty:\n",
    "                seg_scalars['missing_segment'] = 1\n",
    "            else:\n",
    "                seg_scalars['missing_segment'] = 0\n",
    "\n",
    "            # Segment phase counts/durations\n",
    "            seg_phase_durations = get_phase_duration(seg,'phase')\n",
    "            seg_atmphase_durations = get_phase_duration(seg,'atm_phase')\n",
    "            \n",
    "            for k in phases:\n",
    "                seg_phase_durations.setdefault(k, 0)\n",
    "            seg_phase_durations = {f'seg_{k}_dur': v for k, v in seg_phase_durations.items()}\n",
    "            \n",
    "            for k in atm_phases:\n",
    "                seg_atmphase_durations.setdefault(k, 0)\n",
    "            seg_atmphase_durations = {f'seg_{k}_dur': v for k, v in seg_atmphase_durations.items()}\n",
    "\n",
    "            seg_scalars.update(seg_phase_durations)\n",
    "            seg_scalars.update(flight_phase_counts)\n",
    "            seg_scalars.update(seg_atmphase_durations)\n",
    "\n",
    "            \n",
    "            seg_scalars['all_seg_phase_dur'] = sum(seg_phase_durations.values())\n",
    "            seg_dur = (end - start).total_seconds()\n",
    "            \n",
    "            seg_scalars['unscaled_approx_seg_fuel'] = (seg_dur/seg_scalars['real_flight_dur'])*total_flight_fuel\n",
    "            \n",
    "\n",
    "            # --- Column stats (NumPy vectorized)\n",
    "            for col in ts_cols:\n",
    "                #print(col)\n",
    "                arr = seg[col].to_numpy()\n",
    "                valid = ~np.isnan(arr)\n",
    "                if not valid.any():\n",
    "                    for stat in ['start','end','mean','min','max',\n",
    "                                 'sum','nancount']:\n",
    "                        seg_scalars[f'{stat}_{col}'] = np.nan\n",
    "                    seg_scalars[f'nancount_{col}'] = arr.size\n",
    "                    continue\n",
    "\n",
    "                data = arr[valid]\n",
    "                if col in ['longitude','thrust','acp_fuel']:\n",
    "                    seg_scalars[f'start_{col}'] = data[0]\n",
    "                if col in ['altitude','auth_score']:\n",
    "                    seg_scalars[f'end_{col}'] = data[-1]\n",
    "                if col in ['altitude']:\n",
    "                    seg_scalars[f'mean_{col}'] = data.mean()\n",
    "                if col in ['longitude']:\n",
    "                    seg_scalars[f'min_{col}'] = data.min()\n",
    "                if col in ['acp_fuel']:\n",
    "                    seg_scalars[f'max_{col}'] = data.max()\n",
    "                if col in ['altitude','groundspeed','CAS','fuel_flow','fuel',\n",
    "                           'drag','thrust','cl_fuel','enr_fuel','dist_from_ades',\n",
    "                           'acp_fuel','acp_fuelflow']:\n",
    "                    seg_scalars[f'sum_{col}'] = data.sum()\n",
    "                if col in ['mach']:\n",
    "                    seg_scalars[f'nancount_{col}'] = arr.size - data.size\n",
    "\n",
    "                if col == 'altitude' and data.size > 1:\n",
    "                    diff = np.diff(data)\n",
    "                    seg_scalars['total_climb_height'] = diff[diff > 0].sum()\n",
    "\n",
    "            all_segments.append(seg_scalars)\n",
    "\n",
    "    return pd.DataFrame(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train = prepare_flight_segments_final(train_fuel,TRAIN_FLIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adfbb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train = pd.merge(prepared_train,train_flightlist,on='flight_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train.to_csv(f'prep_train_acropole.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_rank = prepare_flight_segments_final(rank_fuel,RANK_FLIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f47e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_rank = pd.merge(prepared_rank,rank_flightlist,on='flight_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "60a40275",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_rank.to_csv(f'prep_rank_acropole.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_final = prepare_flight_segments_final(final_fuel,FINAL_FLIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ab49244",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_final = pd.merge(prepared_final,final_flightlist,on='flight_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ca2fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_final.to_csv(f'prep_final_acropole.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80905a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acropole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
